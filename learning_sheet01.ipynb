{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9478, 1.2474, 1.3238], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True) # whenever operations are done using this tensor, pytorch will make a computational graph \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational graph is now \n",
    "\n",
    "![](.md_images/2022-02-05-16-37-49.png)\n",
    "\n",
    "```\n",
    "x \\\n",
    "    +  =  y\n",
    "2 /\n",
    "```\n",
    "\n",
    "When the summation operation is done, there will be a gradient function `grad_fn` avaliable, which can be seen in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9478, 3.2474, 3.3238], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.3791, 21.0913, 22.0959], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y * 2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.1888, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9304, 4.3299, 4.4318])\n"
     ]
    }
   ],
   "source": [
    "# The only thing we need to calculate the gradient is .backward()\n",
    "z.backward() # calculates the gradient dz/dx, as z depends on y and y depends on x\n",
    "print(x.grad) # in the background this creates a vector Jakobian product to get the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector Jakobian matrix:\n",
    "\n",
    "![](.md_images/2022-02-05-16-48-31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If z is not a scalar, then we must give z.backwar() a vector of teh same size of z as arguemnt. Though the loss function ususally has a single scalar value for its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17.3791, 21.0913, 22.0959], grad_fn=<MulBackward0>)\n",
      "tensor([ 5.1095, 17.3195,  4.4451])\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 2\n",
    "print(z)\n",
    "v = torch.tensor([0.1,1.0,0.001], dtype=torch.float32)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110feb940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoy0lEQVR4nO3deXxU9fX/8ddJQhKSQIAsE2TfIZE97EGlyOCCoNa17mIpKOC3rVat/X7bfr/1p91bwI0iLoAoKgiC1VBXdgk7Cfu+ZWELkD0zn98fGVpKCQnJzNw7M+f5eOSRycyQeecyOfnMnXvPEWMMSimlAk+Y1QGUUkrVjRZwpZQKUFrAlVIqQGkBV0qpAKUFXCmlAlSEPx8sMTHRtG3b1p8PqZRSAW/dunXHjTFJF1/v1wLetm1bsrKy/PmQSikV8ETkwKWu110oSikVoLSAK6VUgNICrpRSAUoLuFJKBSgt4EopFaC0gCulVIDSAq6UUgFKC7hSyi/KKl28v/YghcUVVkcJGn49kUcpFZqOnC7h8Tnr2XToNHuPF/Hcjd2sjhQUdAWulPKpb3cWMGrKMvbkn6NtQgxLc/KsjhQ0tIArpXzC7TZM+WIXD735HcmNolk0cQhjM9qxt6CI3fnnrI4XFLSAK6W87nRxOY++vZY/Ld3Jrb1asOCJwbRPiuP6VAcAmTm5FicMDlrAlVJetfnwaW6espwVu4/zf7dezZ/u6klMZNXbbc3jG9KzZTyfZ+tuFG/QAq6U8gpjDO+uOcgdr67CGMMH4wfzwMA2iMi/3c+ZlsKmQ6fJLSy1KGnw0AKulKq3knIXT32wmZ8v2MKA9s1YPHkovVo1ueR9nZ7dKEu36Sq8vrSAK6XqZf/xIm57ZQUfrT/M5OGdeOuR/jSLjaz2/h2T42iXGEtmtu4Hry89DlwpVWeZ2bn8dN4mwsKENx/ux7CuyTX+GxHBmebgjWX7KCypIL5hAz8kDU66AldKXbFKl5uX/r6dcbPW0TYxlsWTMmpVvM9zpqZQ6TZ8vSPfhymDnxZwpdQVKThbxv1vrOG1b/bwgwGt+WD8IFo1i7mi79G7VRMS46LI1JN66kV3oSilam3t/pM8MWc9hSUV/OHOntzRt2Wdvk9YmDAi1cGijUcoq3QRFRHu5aShQVfgSqkaGWOYsWwv90xfTcPIcBY8PqTOxfs8Z5qDonIXK3ef8FLK0KMrcKXUZZ0rq+RnH27i0y25jEh18Ic7e3rljcfBHRKIjQwnMyf3ivafq3/RFbhSqlo7884yetpyPtuay7M3dmX6A329dtRIVEQ413VNZmlOHi638cr3DDVawJVSl7Rw4xHGTFvBmZIK5jw2kPHXdviPsyrry5nq4Pi5cjYeOuXV7xsqdBeKUurflFe6eWFJDm+vOkB6m6a8fF8fHI2jffJYw7om0yBcyMzOo2+bZj55jGBW4wpcRGaKSL6IbL3o+kkisl1EskXkd76LqJTyl6OnS7h7+ireXnWAxzLaMXfcQJ8Vb4DG0Q0Y1CGRz7NzMUZ3o1yp2uxCeQu44cIrRGQYMAboaYxJA/7g/WhKKX9avus4o6YuZ2fuWV65rw+/GJVKg3Df72V1pjrYf6JYe4TXQY3/O8aYb4GTF109AXjJGFPmuY+eTqVUgHK7DdO+3MUDM9eQEBvJokkZ3NS9ud8ef8Q/e4TrST1Xqq5/XjsDQ0VkjYh8IyL9vBlKKeUfhcUVPPZOFn/I3MktPa7i4yeG0CEpzq8ZHI2j6dWqiTa3qoO6FvAIoBkwEHgamCfVvD0tIuNEJEtEsgoKCur4cEopb9t6pJCbpy5j2a4C/ndMGn+9pxexUdYc1+BMc7DpcCHHCkssefxAVdcCfhiYb6p8B7iBxEvd0Rgz3RiTboxJT0pKqmtOpZQXvb/2ILe/uhKX2/D+jwbx4KC2Xj9E8Eo4U1MAdODxFaprAf8YGAYgIp2BSOC4lzIppXyktMLF0x9s4pmPttC/bTMWT8qgT+umVseiY3Ic7ZNiydRRa1ekxtdLIjIXuA5IFJHDwC+BmcBMz6GF5cBDRo8BUsrWDpwoYsLs9eQcO8Pk73Xkyes7Ex5m3ar7Ys7UFGYs20thcQXxMdojvDZqLODGmHuruel+L2dRSvnIP3Ly+PG8jYSJMPPhdL7X1WF1pP8wMs3Ba9/s4asd+dzau4XVcQKCnkqvVBCrdLn53WfbeeydLNokxLB4UoYtizdAz5ZNSG4URWaOHo1SW3oqvVJB6vi5MibP3cDKPSe4t38rfnlLGtEN7Nt3+3yP8AUbjlBa4bJ1VrvQFbhSQWjdgZPcPGUZ6w6c4nd39ODF23sEREF0pqVQXO5i5R49JqI2tIArFUSMMby5Yh93v76aqIhw5j8+mLvSW1kdq9YGtU+gUVQEn2/Vo1FqQ3ehKBUkisoqeeajzSzefIzruzn4413eGbzgT5ERYVzXNZl/bKvqEW6no2TsSFfgSgWB3flnGfPyCj7dcoxnbvDu4AV/c6Y6OFFUzvqD2iO8JroCVyrAfbLpKM98tJmYyHBmPzaAwR0ueVJ0wLiuSxKR4WFkZufSr632CL8cXYErFaDKK938+pNsJs3dQLfmjVk8aWjAF2+ARtENGNwxgcycPO0RXgMt4EoFoGOFJdwzfRVvrtjPo0Pa8d64gaTE+27wgr85U1M4cKKYnXnaI/xytIArFWBW7D7OqCnL2Z57lmk/6M3/3OKfwQv+dH1qMiJoi9kaBNf/ulJBzO02vPzVbh54Yw1NYyNZNHEIo3pcZXUsn0huFE3vVk10yEMNtIArFQAKiysYNyuL33++g5t7XMXCJ4bQMbmR1bF8ypmWwpYjhRw5rT3Cq6MFXCmbyz5ayC3TlvP1jgJ+dUsqUywcvOBPTs+otaW6G6VaWsCVsrF5WYe4/ZWVlFe6ef9Hg3h4SDtLBy/4U/ukODomx+lulMvQAq6UDZVWuHj2o8387MPN9G3TlMWTM+jbxvrBC/7mTHWwZt9JTheXWx3FlrSAK2Uzh04Wc8drK3lv7SGeGNaBWWMHkBgXZXUsSzjTUnC5DV9uz7c6ii1pAVfKRr7cnsfNU5Zx4EQxMx5M5+mRXUO6H0iPFvGkNI7WUWvVCP53QpQKAC634c9LdzLtq92kNm/Ma/f3pXVCjNWxLHe+R/iH6w5rj/BL0BW4UhY7ca6MB2euYdpXu7k7vRXzHx+sxfsCzjQHJRUulu/SHuEX0xW4UhZaf/AUT8xZz4micn77/e7c3a+11ZFsZ0C7BBpFR/B5di7Xp9pzHJxVtIArZQFjDO+sOsBvluSQEh/N/AmDubpFvNWxbCkyIozveXqEV7rcRARZ24D60C2hlJ8VlVXy5Hsb+eWibK7plMTiiUO1eNfAmZrCqeIK1h3QHuEXqrGAi8hMEckXka2XuO2nImJEJPB7WCrlB7vzz3HryytYvPkoT4/swt8eTCc+JjAHL/jTted7hOtJPf+mNivwt4AbLr5SRFoBTuCglzMpFZSWbD7GmGnLOVFUzjuPDuCJYR0JC+FDBK9EXFQEQzomkJmTqz3CL1BjATfGfAucvMRNfwZ+BujWVOoyKlxu/veTHJ54dz2dUxqxZHIGGZ30ReuVGpmWwqGTJWzPPWt1FNuo0z5wERkDHDHGbKrFfceJSJaIZBUUFNTl4ZQKWLmFpdw7fTUzV+zj4cFteX/cIJrHN7Q6VkAa3s3h6RGuu1HOu+ICLiIxwM+B/6nN/Y0x040x6caY9KSkpCt9OKUC1so9xxk1dRk5x84w5d7e/Gp0GpERetxAXSU1iqJv66Zk5mh3wvPq8mzqALQDNonIfqAlsF5EUrwZTKlAZYzh1a/3cP+MNcQ3bMDCJ4YwumdwDl7wN2eag+yjZzh8qtjqKLZwxQXcGLPFGJNsjGlrjGkLHAb6GGP0z6IKeYUlFYybtY7ffradG7s3Z+HEDDo5gnvwgj+NSK1aJ+pulCq1OYxwLrAK6CIih0VkrO9jKRV4co6eYfS05Xy1PZ//GZXKtHt7ExcCgxf8qV1iLJ0dcbobxaPGZ5cx5t4abm/rtTRKBagP1x3m+QVbaBLTgPfGDSS9bTOrIwUtZ2oKr3y9m1NF5TSNjbQ6jqX0HRWl6qG0wsVz87fw1Aeb6NO6KYsnDdXi7WPONAduA19oj3At4ErV1fnBC3O/O8iE6zowa2x/khqF5uAFf+reIp7m8dFk6qxMbWalVF18tT2f/3p/I25j+NuD6YzQLnl+IyI4Ux28n3WIknIXDSNDt0e4rsCVugIut+FPmTt45K21XNWkIYsnZWjxtoAzLYXSCjfLdoX2yYFawJWqpZNF5Tz85ndM+XI3d/RtyYLHB9MmIdbqWCGpf7tmNI6OCPnmVroLRala2OAZvHC8qJyXbu/O3f1aIaKNqKzSIDyM4d0cfBHiPcJD86dWqpaMMcxatZ+7Xl9FWJjw0fjB3NO/tRZvG3CmOjhVXMHa/aHbI1xX4EpVo7i8kp/P38LHG48yrEsSf767F01iQvu4Yzu5pnMSkRFhZObkMqhDgtVxLKErcKUuYU9B1eCFhZuO8tMRnXnjoX5avG0mNiqCoR0TyczOC9ke4VrAlbrI37ccY8y0FRw/V847j/Zn0vBOOnjBppxpDo6cLiHn2Bmro1hCC7hSHhUuNy8syWHCnPV0TI5j8aQMhnbSFsh2dn03B2Eh3CNcC7hSQP6ZUu772xr+tmwfDw1qw7wfDeKqJjp4we4S4qJIb9MsZA8n1AKuQt7qvSe4acpythwp5K/39OLXY67WwQsBxJnmYNuxMxw6GXo9wvVZqkKWMYbXv9nDfTPW0Dg6goUThzCmVwurY6krdP5M2M9DsDeKFnAVks6UVjB+9jpe/Pt2RqY5WDhxCJ118EJAapMQS9eURiG5G0WPA1chZ9uxM0yYvY5Dp0r4xc3dGJvRTk/MCXDOVAfTvtrNiXNlJMSFTkdIXYGrkDJ//WFue2UFxeUu3hs3kMeGttfiHQScaSkh2SNcC7gKCWWVLp5fsIWfzNtEr1ZNWDw5g346eCFopF3VmKvio0PucELdhaKC3uFTxTw+Zz2bDxcy/toOPOXsHLLNj4KViOBMS2HudwcpLq8kJjI0Sps+i1VQ+3pHPqOmLmdfQRGvP9CXZ2/sqsU7SDnTHJRVuvl253Gro/iNPpNVUHK7DX/5x04eeWstKY2jWTQpg5FpKVbHUj7Uv20z4hs2CKmJ9aHxOkOFlFNF5fzX+xv5ZmcBt/dpwQu3dg/psVuhIiI8jOHdkvliWz4VLjcNQuCVVo0/oYjMFJF8Edl6wXW/F5HtIrJZRBaISBOfplSqljYdOs2oqctZtecE/++27vzxzp5avEOIMzWFwpIK1u47aXUUv6jNn6i3gBsuum4pcLUxpgewE3jOy7mUuiLGGGavPsCdr60C4MMJg/jBAB28EGqu6ZxIVERYyJzUU2MBN8Z8C5y86LpMY0yl58vVQEsfZFOqVkrKXfx03iZ+8fFWBnVIYPGkDHq0bGJ1LGWBmMgIhnZKIjM7NyR6hHtjJ9GjwN+ru1FExolIlohkFRSE9gRp5X37jhdx2ysrWLDxCD++vjNvPtyPprE6eCGUOdMcHC0sJfto8PcIr1cBF5HngUpgTnX3McZMN8akG2PSk5K0t7Lyns+25jJ66nJyz5Ty1iP9efJ6HbygYHjXZE+P8OA/GqXOBVxEHgZGAfeZUHitomyj0uXmxU+3MX72OtonxbJ4UgbXdtbFgaqSEBdFv7ah0SO8TgVcRG4AfgaMNsaEXhNeZZn8s6X8YMYaXv92L/cPbM288YNo2TTG6ljKZpxpKWzPPcuBE0VWR/Gp2hxGOBdYBXQRkcMiMhaYBjQClorIRhF5zcc5leK7fSe5ecpyNh8+zZ/v7slvbu1OVIQeIqj+k9PTI3xpkK/CazyRxxhz7yWufsMHWZS6JGMMM5bt46XPttO6WQyzxvana0pjq2MpG2vVLIZuzRvzeXYujw1tb3Ucnwn+U5VUQDtbWsGE2et54dNtjOjmYNHEIVq8Va04Ux1kHTjF8XNlVkfxGS3gyrZ25J5l9LQVLN2Wx/M3dePV+/vQKLqB1bFUgHCmOTAGvtgWvLtRtIArW/p4wxFufXkF58oqefexAfzwGh28oK5MavPGtGjSMKh7hGszK2UrZZUufrN4G7NWH6B/22ZM+0FvkhtHWx1LBaCqHuEO5qw5SFFZJbFRwVfudAWubOPI6RLuen01s1YfYNw17ZnzwwFavFW9OFNTKK908+3O4DwLPPj+JKmA9O3OAp58bwMVLsNr9/fhhqubWx1JBYF+bZvSNKYBmTl53Ng9+J5TWsCVpdxuw9Qvd/OXL3bSObkRr97fh/ZJcVbHUkGiqke4g8zs3KDsER5cP40KKKeKynn07bX8+R87ubVXCxY8MViLt/I6Z6qDM6WVrNkbfD3CdQWuLLH58GkmzF5PwdkyfnPr1dynvbuVjwztlER0gzAyc3LJ6JRodRyv0hW48itjDO+uOcgdr1YNXpg3fhD3D2yjxVv5TMPIcK7plERmdl7Q9QjXAq78pqTcxVMfbObnC7YwoH0zPpmUQa9WTayOpUKAMy2F3DOlbDlSaHUUr9JdKMov9h8vYvzsdezIO8uTwzsxeXgnwrV3t/KTf/UIzwuqaU26Alc+l5mdyy2ewQtvPtyPH4/orMVb+VXT2Ej6t2tGZk5wDXnQAq58ptLl5qW/b2fcrHW08wxeuK5LstWxVIgamZbCzrxz7DsePD3CtYArnyg4W8b9b6zhtW/2cN+A1nyggxeUxUb8s0d48KzCtYArr1u7/yQ3T1nGxkOn+eOdPXnhNh28oKzXsmkMaVc15vMgam6lBVx5TdXghb3cM301MZHhLHh8CN/v29LqWEr9kzM1hfUHT5F/ttTqKF6hBVx5xbmySp54dz2/WbKN4V2TWTQpg27NdfCCspd/9QjPtzqKV2gBV/W2M+8so6ct57OtuTx3Y1def6AvjXXwgrKhrimNaNWsIZnZwbEfXI8DV/WycOMRnv1oC7FREcx5bCCDOiRYHUmpaokIztQUZq06wLmySuICvEe4rsBVnZRXuvnlwq08+d5Grm7RmE8nZ2jxVgHBmeqg3OXmmx2B3yO8xgIuIjNFJF9Etl5wXTMRWSoiuzyfm/o2prKTo6dLuHv6Kt5edYAfDm3Huz8cqIMXVMBIb9uMZrGRQXFST21W4G8BN1x03bPAF8aYTsAXnq9VCFi+6zijpi5nV945XrmvD8/fnBp0PZZVcAsPE67vlsyX2/Mpr3RbHadeavzNM8Z8C1zcSHcM8Lbn8tvArd6NpezG7TZM+3IXD8xcQ2JcJAsnDuGmIJxwokKDMzWFs6WVrN57wuoo9VLXPfgOY8wxz+VcwOGlPMqGCosr+PG8jXy5PZ8xva7ixdu7ExMZ2G/+qNCW0SmRhg3CyczJ5ZrOSVbHqbN6v/Y1VQ12q22yKyLjRCRLRLIKCgL/TYNQs/VIITdPXcayXQX835g0/nJ3Ly3eKuBFNwjn2s5JLM3Jw+0O3B7hdS3geSLSHMDzudqj4o0x040x6caY9KSkwP1LF4reX3uQ219didttmPejQTwwqK0OXlBBw5nmIO9MGZsDuEd4XQv4IuAhz+WHgIXeiaPsoLTCxdMfbOKZj7YwoF0zFk8eSu/WeqCRCi7f65pMeJgE9Ek9tTmMcC6wCugiIodFZCzwEjBCRHYB13u+VkHgwIkibn9lJR+sO8zk4Z1465H+NIuNtDqWUl7XJCaSAe2akZkTuM2tatyZaYy5t5qbhns5i7LY0pw8fjJvI2EivPlwP4Z11d7dKrg5Ux386pMc9hSco0NSnNVxrpgewKuodLn53Wfb+eE7WbRNqBq8oMVbhQJnWgpQtXgJRFrAQ9zxc2U8OPM7Xvl6D/f2rxq80KqZDl5QoeGqJg3p3iI+YPeDawEPYesOVA1eWHfgFL+/owcv3t6d6AY6eEGFFmeqg/UHT5N/JvB6hGsBD0HGGN5csY+7X19NdINw5j8+mDvTW1kdSylL/HM3yrbA242iBTzEFJVVMmnuBn79SQ7XdUlm0cQM0q6KtzqWUpbp7IijTUIMmQE4ak1PqQshu/PPMn72evYWnOOZG7ryo2vaExamJ+ao0FbVI9zBWyv3c7a0gkYBNIxEV+AhYtGmo4yetoLTxeXMfmwAE67roMVbKQ9nWgoVLsPXAdYjXAt4kCuvdPOrRdlMnruBbs0bs3jSUAZ3SLQ6llK20qd1UxJiIwPupB7dhRLEjhWW8MSc9aw/eJpHh7TjuZu6au9upS6hqke4gyVbjlFW6SIqIjCOxtLf5iC1YvdxRk1Zzo7cs0z7QW/+5xYdvKDU5Yy82sG5skpW7714/IF96W90kHG7DS9/tZsH3lhDs9hIFk7MYFSPq6yOpZTtDe6QSExkOJ8H0Ek9WsCDSGFxBeNmZfH7z3cwqsdVfPzEEDomB15/B6WsEN0gnOu6BFaPcC3gQSL7aCG3TFvONzsL+PXoNP56Ty9io/QtDqWuhDM1hYKzZWw8fNrqKLWiBTwIzMs6xO2vrKS80s174wbx0GAdvKBUXQzrkkxEmATMST1awANYaYWLZz7czM8+3Ex626YsmZxB3zY6eEGpuoqPacDA9glk5gTGfnAt4AHq4Ilivv/qSt7POsTEYR1559EBJMRFWR1LqYDnTHOwt6CI3fnnrI5SIy3gAeiLbXmMmrqMQyeLeeOhdJ4a2YVwPatSKa8YkeoACIhVuBbwAOJyG/7w+Q7Gvp1Fq2YxLJ40lOHdHFbHUiqoNI9vSM+W8QGxH1wLeIA4ca6MB2euYdpXu7mnXys+mjCY1gk6eEEpX3CmpbDx0GlyC+3dI1wLeABYf/AUo6YuJ2v/KX73/R689P0eOnhBKR9yenaj2L1HuBZwGzPG8PbK/dz9+ioahIfx0YTB3NVPBy8o5Wsdk+Nolxhr+1FreqaHTRWVVfLs/C18suko13dL5o939iI+JnD6FCsVyM73CH9j+T4KSyqIb2jP3716rcBF5Mciki0iW0VkrohEeytYKNudf44xL69gyeajPD2yC9MfSNfirZSfOdMcVLoNX+/ItzpKtepcwEWkBTAZSDfGXA2EA/d4K1ioWrz5KGOmLedUUTmzxg7giWEddfCCUhbo1aopiXFRtu4RXt9dKBFAQxGpAGKAo/WPFJoqXG5e/HQ7M1fso0/rJrx8Xx+axze0OpZSISs8TBiRmsyijUdt2yO8zitwY8wR4A/AQeAYUGiMybz4fiIyTkSyRCSroCCwxhX5S25hKfdOX83MFft4ZEhb3hs3SIu3UjbgTE2hqNzFyj0nrI5ySfXZhdIUGAO0A64CYkXk/ovvZ4yZboxJN8akJyUl1T1pkFq55zijpi4j59gZpt7bm1/ekkZkhB4cpJQdDO6YQGxkuG2PRqlPpbge2GeMKTDGVADzgcHeiRX8jDG8+vUe7p+xhviGDVg0cQi39NTBC0rZSVREONd1TWZpTh4uG/YIr08BPwgMFJEYqepdOhzY5p1Ywa2wpIJxs9bx28+2c1P35iycmEHH5EZWx1JKXYIz1cHxc+VsPHTK6ij/oc5vYhpj1ojIh8B6oBLYAEz3VrBglXP0DBPmrOPIqRJ+eUsqD2vvbqVsbVjXZBqEV/UI79ummdVx/k29drYaY35pjOlqjLnaGPOAMabMW8GC0QdZh7jtlRWUVrh4/0cDeWRIOy3eStlc4+iqHuGfZ+dijL12o+i7ZX5QWuHiufmbefrDzfRt05Qlk4fa7i+5Uqp6zrQU9p8otl2PcC3gPnboZDF3vLaSud8d4olhHZg1dgCJOnhBqYAyotv5HuH2OqlHC7gPfbU9n1FTl3PgRDEzHkzn6ZFddfCCUgEoJT6anq2a2O5wQi3gPuByG/6UuYNH3lpLiyYNWTwpg+tTdfCCUoFsZJqDTYcLOVZYYnWUf9IC7mUni8p5+M3vmPLlbu7s25L5jw+mTUKs1bGUUvXkTE0BYKmNdqNoAfeiDQdPMWrKMtbsO8lvv9+d39/ZUwcvKBUkOibH0T4p1laj1rSAe4Exhlmr9nPX66sICxPmTxjM3f1aWx1LKeVlztQUVu89QWFxhdVRAC3g9VZcXsmP39/Ify/MZminJBZPyuDqFvFWx1JK+cD5HuFf2aRHuBbwethTcI5bX17Bok1VgxdmPJhOk5hIq2MppXykV8smJDWKIjPHHkej6Ei1Ovr7lmM8/eFmIiPCeOfRAWR0SrQ6klLKx8LChBGpDj7ecITSCpfl73HpCvwKVbjcvLAkhwlz1tPJEcfiSRlavJUKIc5UB8XlLlbuOW51FF2BX4n8M6VMfHcD3+0/ycOD2/Lzm7pp726lQsygDgnERUWQmZ3H97pae36HVp9aWr33BDdNWc6WI4X89Z5e/Gq0Dl5QKhRFRYQzzCY9wrUC1cAYw+vf7OG+GWto3DCChROHMKZXC6tjKaUs5Ex1cKKonPUHre0RrrtQLuNMaQVPzdtEZk4eN3dvzm/v6EFclG4ypULddV2SPD3Cc+nX1rrOoroCr8a2Y2cYPXU5X27P579HpTLtB721eCulAGgU3YDBHRLJzMmztEe4FvBLmL/+MLe9soLichdzxw1kbIYOXlBK/TtnmoMDJ4rZmWddj3At4Bcoq3Tx/IIt/GTeJnq1asKSyUMtfXmklLKvf/YIt7DFrBZwj8OnirnztVXMWXOQ8dd2YPbYASQ10sELSqlLS24cTe/WTSwd8qAFHPh6R9XghX0FRbz+QF+evbErEeG6aZRSl+dMTWHLkUKOnramR3hIVymX2/DnpTt55K21pDSO5pNJGYxMS7E6llIqQIxMs3Y3SsgW8JNF5Tzy1lr++sUubu/dkgWPD6Ftog5eUErVXvukODomx1m2G6VeBVxEmojIhyKyXUS2icggbwXzpU2HTnPL1OWs3nOCF2/vzh/u7EHDSB28oJS6cs5UB2v2neR0cbnfH7u+K/C/Ap8ZY7oCPYFt9Y/kO8YYZq8+wJ2vrQLgwwmDuLd/az1EUClVZ860FFxuw5fb/d8jvM4FXETigWuANwCMMeXGmNNeyuV1JeUufjpvE7/4eCuDOyawZHIGPVo2sTqWUirA9WgRj6NxlCWj1upzamE7oAB4U0R6AuuAJ40xRRfeSUTGAeMAWre2ZszYvuNFTJi9jh15Z/nJiM5MHNaRsDBddSul6u98j/CP1vm/R3h9dqFEAH2AV40xvYEi4NmL72SMmW6MSTfGpCclJdXj4erms625jJ66nLwzpbz9SH8mD++kxVsp5VXO1BRKKlws3+XfHuH1KeCHgcPGmDWerz+kqqDbQqXLzYufbmP87HW0T45j8eShXNPZ/39AlFLBb2D7BBpFRfh91Fqdd6EYY3JF5JCIdDHG7ACGAznei1Z3+WdKmTh3A9/tO8kDA9vwi1HdiIrQo0yUUr4RGRHGsK7J/GNbPpUut99OBKxve71JwBwRiQT2Ao/UP1L9rNl7golzN3CutJK/3N2LW3tr726llO+NTEth0aajrDtwigHtE/zymPUq4MaYjUC6d6LUjzGGGcv28dJn22nTLIbZYwfQJaWR1bGUUiHi2i5JRIaHkZmT57cCHhRnYp4trWDC7PW88Ok2nKkOFk4cosVbKeVXcVERDOmYQGZOrt96hAd8Ad+Re5bR01awdFsev7i5G6/c14dG0Q2sjqWUCkHOtBQOnSxhe+5ZvzxeQI+Y+XjDEZ6bv4W46Ajm/nAg/dtp726llHWGd0tGBDKz8+jWvLHPHy8gV+BllS7+++Ot/Nf7G+neMp4lkzO0eCulLJfcKJo+rZv67XDCgCvgR06XcNfrq5m1+gA/uqY97z42gORG0VbHUkopoKq5VfbRMxw+VezzxwqoAv7NzgJGTVnG3vxzvHZ/X567qZsOXlBK2YrTM1NgqR9azAZE9XO7DX/9xy4efvM7HI2jWTQpgxuu1sELSin7aZcYS2dHHJ/7YchDQBTw5z/eyp//sZPberVgweNDaKeDF5RSNuZMTeG7fSc5VeTbHuEBUcDv7d+K39x6NX+8q6cOXlBK2Z4zzYHbwBc+7hEeEAW8R8sm3D+wjQ5eUEoFhO4t4klpHO3zWZkBUcCVUiqQiAjONAff7iqgpNzls8fRAq6UUj7gTE2htMLNsl0FPnsMLeBKKeUDA9o3o1F0hE8n1msBV0opH2gQHsbwrsl8sS2PSpfbJ4+hBVwppXzEmZbCqeIK1u4/5ZPvrwVcKaV85NrOSURGhPmsN4oWcKWU8pHYqAiGdkwkMzvPJz3CtYArpZQPOdMcHDldQs6xM17/3lrAlVLKh4Z3czCsSxIut/dX4AE90EEppewuMS6KNx/p75PvrStwpZQKUFrAlVIqQNW7gItIuIhsEJHF3giklFKqdryxAn8S2OaF76OUUuoK1KuAi0hL4GZghnfiKKWUqq36rsD/AvwMqPZEfxEZJyJZIpJVUOC7rlxKKRVq6lzARWQUkG+MWXe5+xljphtj0o0x6UlJSXV9OKWUUhepzwp8CDBaRPYD7wHfE5HZXkmllFKqRuKN8/NF5DrgKWPMqBruVwAcqOfDJQLH6/k9fMnu+cD+Ge2eD+yf0e75wP4Z7ZSvjTHmP3Zh+PVMzEsFuFIikmWMSfdGHl+wez6wf0a75wP7Z7R7PrB/RrvnAy8VcGPM18DX3vheSimlakfPxFRKqQAViAV8utUBamD3fGD/jHbPB/bPaPd8YP+Mds/nnTcxlVJK+V8grsCVUkqhBVwppQKWbQq4iNwgIjtEZLeIPHuJ29uIyBcisllEvvb0YTl/m0tENno+Fvko30wRyReRrdXcLiIyxZN/s4j0ueC2h0Rkl+fjIV/k80JGO2zDriKySkTKROSpi2677PPDJhn3i8gWzzbMsijffZ7/2y0islJEel5wm1224eUy2mEbjvHk2+hpA5JxwW1++V2uNWOM5R9AOLAHaA9EApuA1Ivu8wHwkOfy94BZF9x2zg8ZrwH6AFuruf0m4O+AAAOBNZ7rmwF7PZ+bei43tVNGG23DZKAf8AJVJ4bV+vlhdUbPbfuBRIu34eDzzy/gxgueh3bahpfMaKNtGMe/3h/sAWz3XPbb73JtP+yyAu8P7DbG7DXGlFN1av6Yi+6TCnzpufzVJW73KWPMt8DJy9xlDPCOqbIaaCIizYGRwFJjzEljzClgKXCDzTL6RU35jDH5xpi1QMVFN9Xm+WF1Rr+oRb6VnucZwGrg/CtVO23D6jL6RS3ynTOeig3EAucv++13ubbsUsBbAIcu+Pqw57oLbQJu91y+DWgkIgmer6M9L3VWi8itPk1avep+htr8bP5yuSx22IbVsdM2vBwDZIrIOhEZZ3UYYCxVr7jAvtvwwoxgk20oIreJyHZgCfCo52rbbcNAGmr8FDBNRB4GvgWOAC7PbW2MMUdEpD3wpYhsMcbssShnoNJtWH8Znm2YDCwVke2e1Z7ficgwqopjRk33tUo1GW2xDY0xC4AFInIN8H/A9f7OUBt2WYEfAVpd8HVLz3X/ZIw5aoy53RjTG3jec91pz+cjns97qTqlv7fvI/+H6n6GGn82P6o2i022YXXstA2rdcE2zAcWULXbwu9EpAdVQ1bGGGNOeK621TasJqNttuEFeb4F2otIIjbbhmCfAr4W6CQi7UQkErgH+LcjIUQkUUTO530OmOm5vqmIRJ2/D1VtbnP8lvxfFgEPeo70GAgUGmOOAZ8DTk/OpoDTc50VLpnRRtuwOjU+P6wmIrEi0uj8Zar+ny95lIOPc7QG5gMPGGN2XnCTbbZhdRlttA07ioh4LvcBooAT2Ot3uYqV76Be+EHVERI7qXqn/HnPdf8LjPZcvgPY5bnPDCDK/Osd7S1U7SPfAoz1Ub65wDGq3rw6TNVLv/HAeM/tArzsyb8FSL/g3z4K7PZ8POLDbVinjDbahime688Apz2XG1f3/LBTRqqO7tjk+cj2VcZa5JsBnAI2ej6yLvc7ZqeMNtqGz3gefyOwiqrdOn79Xa7th55Kr5RSAcouu1CUUkpdIS3gSikVoLSAK6VUgNICrpRSAUoLuFJKBSgt4EopFaC0gCulVID6/+u4LUv9JrSlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.plot(x.detach(), x.grad.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyModel(\n",
       "  (layer1): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information from https://www.youtube.com/watch?v=M0fX15_-xrY\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DIM_IN = 1000\n",
    "HIDDEN_SIZE = 100\n",
    "DIM_OUT = 10\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Linear(1000, 100)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "some_input = torch.randn(BATCH_SIZE, DIM_IN, requires_grad=False)\n",
    "ideal_output = torch.randn(BATCH_SIZE, DIM_OUT, requires_grad=False)\n",
    "\n",
    "model = TinyModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0660, -0.0286, -0.0124, -0.0448, -0.0034,  0.0432, -0.0301,  0.0754,\n",
      "         0.0533,  0.0261], grad_fn=<SliceBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.layer2.weight[0][0:10])\n",
    "print(model.layer2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(172.1098, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiser = torch.optim.SGD(model.parameters(), lr=0.001) # the optimiser is responsible for adjusting the weights. model.parameters() are the weights\n",
    "\n",
    "prediction = model(some_input)\n",
    "\n",
    "loss = (ideal_output - prediction).pow(2).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7701e+00,  1.6638e+00, -8.1883e-01,  3.0747e+00, -9.7596e-02,\n",
      "          1.1499e+00,  6.3433e-01, -1.0187e+00, -2.6175e+00, -1.4519e+00,\n",
      "          4.5643e-01, -1.4644e+00, -2.4255e+00,  2.6985e-01,  3.1476e+00,\n",
      "         -8.8200e-01, -2.1003e-01, -6.3955e-01,  1.1261e+00, -2.2280e+00,\n",
      "          4.9854e-01, -9.4888e-01,  3.9972e-01, -2.5047e+00, -1.3480e+00,\n",
      "         -2.2966e+00, -8.7272e-01, -1.5762e+00, -2.3289e+00, -7.5630e-01,\n",
      "         -1.3897e+00, -1.0016e+00,  5.0188e-01,  4.3958e-01, -2.4936e-03,\n",
      "          1.5737e+00, -8.0517e-01, -2.0990e-01, -1.5634e+00, -3.4382e+00,\n",
      "         -4.5506e-01, -2.0725e+00,  8.7222e-01, -1.5890e+00, -7.8006e-02,\n",
      "         -2.1267e-01, -9.4774e-01,  1.6245e+00,  1.0315e+00,  5.2008e-01,\n",
      "          3.5028e+00, -1.5476e+00, -1.4709e+00, -8.7902e-01, -2.7155e+00,\n",
      "         -2.1635e+00, -3.2861e+00, -1.5005e+00, -9.0619e-01, -2.9491e+00,\n",
      "         -2.0101e+00,  7.9420e-01, -2.2553e-01,  1.1952e+00, -4.8266e+00,\n",
      "          1.6508e+00,  5.3247e-01, -4.9397e-01, -4.0224e-01, -1.4104e-01,\n",
      "         -1.9980e+00, -2.8823e+00, -2.9411e+00, -1.8244e+00, -3.8655e+00,\n",
      "         -2.5869e+00, -2.0425e+00, -1.4858e+00,  1.2801e-01, -2.3952e-01,\n",
      "          5.0486e-01,  1.0299e+00,  1.0218e+00, -2.8973e+00, -2.2916e+00,\n",
      "         -2.3222e-01, -5.9772e-01, -1.9415e+00,  2.1367e-01, -2.1802e+00,\n",
      "          1.4559e+00, -1.0128e+00, -2.4173e+00,  2.2313e+00, -7.2231e-01,\n",
      "         -1.4516e+00, -1.6934e+00,  1.3222e+00, -6.5136e-01,  8.4070e-01],\n",
      "        [ 1.0424e+01,  7.0889e+00, -1.9170e+00,  9.5709e+00,  3.0315e+00,\n",
      "          7.6728e+00,  2.1204e+00,  9.6644e+00,  3.9945e+00,  3.8127e+00,\n",
      "          6.3180e+00,  4.8143e+00,  3.4279e+00,  7.1094e+00,  5.7018e+00,\n",
      "          8.3548e+00,  1.9347e+00,  4.8176e+00,  5.3300e+00,  2.0573e+00,\n",
      "          2.0638e+00, -1.4406e+00,  4.4755e+00,  5.1876e-01, -1.4257e+00,\n",
      "          1.5794e+00,  4.9185e+00,  4.9659e+00,  7.0887e-01,  1.2443e+00,\n",
      "          1.8873e+00,  1.5167e+00,  4.2675e+00,  1.1904e+00,  9.0134e+00,\n",
      "          4.9743e+00,  1.2051e+00,  1.8718e+00,  1.8691e+00,  8.6723e+00,\n",
      "          7.0739e+00,  8.0560e+00,  4.4154e+00,  9.0557e+00,  3.5278e+00,\n",
      "          3.0155e+00,  1.5929e+00,  5.9981e+00,  2.4945e+00,  4.8899e+00,\n",
      "          3.5205e+00,  3.3134e+00,  4.5446e-01,  1.5666e+00, -8.2649e-01,\n",
      "         -3.4545e-01,  5.6880e+00,  4.5404e+00, -8.9417e-01,  1.4593e-01,\n",
      "         -8.0512e-01,  4.6438e+00,  1.5150e+00,  3.3849e+00,  4.3649e+00,\n",
      "          5.5148e+00,  3.0834e+00,  9.9216e+00,  5.3795e-02,  1.4335e+00,\n",
      "          1.1452e+01, -6.3057e-02,  8.0496e+00,  2.8336e+00,  2.5473e+00,\n",
      "         -1.7115e+00, -1.8333e+00,  8.0932e+00,  7.4657e+00,  5.2481e+00,\n",
      "          4.5330e-01,  2.0741e+00,  4.1488e+00,  1.5141e+00,  6.9695e-01,\n",
      "          1.0153e+00,  3.7755e+00,  3.7482e+00,  1.4788e+00, -5.5429e-01,\n",
      "          2.8988e+00,  3.3042e+00,  5.2291e+00,  3.4624e+00,  2.0646e+00,\n",
      "          1.1923e+01,  2.4957e+00,  5.7313e+00, -8.0480e-01,  5.0192e+00],\n",
      "        [ 1.0296e+00, -2.6328e+00,  6.0147e-01, -3.8382e+00,  6.0882e-01,\n",
      "          1.6932e+00,  3.7357e-02,  2.8473e+00, -5.2590e+00, -2.2433e+00,\n",
      "          8.8793e-01, -3.3587e+00, -8.5907e-01, -9.4302e-01, -2.6235e+00,\n",
      "          2.3394e-01,  4.8613e-01, -1.0927e+00,  3.8224e-01, -1.1560e+00,\n",
      "          3.3589e-01,  6.5377e-01, -1.5657e+00,  3.2762e-01, -1.1012e+00,\n",
      "         -1.6331e+00, -4.7687e-01, -2.9424e+00,  1.4380e+00, -8.9752e-01,\n",
      "          6.3438e-01,  2.3999e+00, -1.8109e+00, -2.0024e+00, -1.6611e-03,\n",
      "          1.5504e+00, -3.6698e-01,  9.7504e-01, -1.4465e+00, -2.5209e+00,\n",
      "         -1.7301e+00,  1.0618e+00, -5.0807e+00, -3.2293e+00, -1.7103e+00,\n",
      "          4.1565e+00, -4.7418e-01,  2.1527e-01, -2.9526e+00, -1.4061e+00,\n",
      "         -3.4039e+00, -8.2663e-01,  4.0523e-01, -3.5124e+00, -1.3157e+00,\n",
      "          3.1463e+00,  2.1633e+00,  1.1334e+00, -9.2092e-02, -4.4200e+00,\n",
      "          1.4913e+00, -9.2824e-01,  9.7152e-01, -1.8647e-01, -1.9220e+00,\n",
      "         -2.9791e+00, -3.8770e-01, -1.2875e+00, -4.0204e+00,  1.4894e+00,\n",
      "         -5.6152e-01, -1.7619e+00, -4.4776e-01, -3.2057e+00, -6.3553e-01,\n",
      "         -1.9688e+00,  4.0951e+00, -3.9023e-01, -7.5777e-02, -1.2421e+00,\n",
      "          5.5625e-01,  5.8146e-01, -2.8932e+00, -7.1791e-01,  2.1226e-01,\n",
      "          1.8019e-01,  2.8907e-01, -1.0338e+00,  9.8818e-01,  7.9004e-01,\n",
      "         -2.1042e+00, -3.0021e+00, -8.6517e-02, -2.8068e+00, -2.6631e+00,\n",
      "         -4.3264e-01, -3.2946e+00, -2.2799e+00, -8.1122e-01, -7.7853e-01],\n",
      "        [-2.7938e+00,  8.0000e+00, -1.7911e+00, -1.8953e+00, -1.6663e-01,\n",
      "         -3.3497e+00, -3.7750e+00,  8.8926e-01,  7.7316e-01, -6.7176e+00,\n",
      "         -3.8147e+00, -1.0783e+00, -4.9229e+00,  6.2596e+00,  3.3813e+00,\n",
      "         -5.2949e+00, -4.6926e-01, -3.7584e+00, -8.9158e-01,  3.8265e+00,\n",
      "         -2.0517e+00, -5.1158e+00, -1.3116e+00,  4.4420e-01,  2.5880e+00,\n",
      "         -6.0787e+00, -1.6238e+00, -9.3514e-01, -1.5182e+00,  2.5163e+00,\n",
      "         -4.9000e-02, -6.1283e-01,  6.5430e+00, -4.0004e-01, -3.4352e+00,\n",
      "         -5.4015e+00,  1.1068e+00,  2.2215e+00, -5.1577e+00, -4.9521e-01,\n",
      "         -1.6132e+00,  1.3384e-01,  3.7410e-01,  1.3945e-01, -1.2203e+00,\n",
      "         -3.1113e+00, -3.7982e+00,  1.4896e+00,  3.1580e+00, -7.3794e+00,\n",
      "          2.6868e+00,  1.3204e+00,  2.2124e-01, -8.9310e-01, -2.2250e-01,\n",
      "         -1.8502e+00,  2.8349e-01, -2.1416e+00, -1.1067e+00,  1.7035e+00,\n",
      "         -3.4066e+00,  2.1041e+00,  3.5994e-01, -1.4839e-01,  1.2309e-02,\n",
      "          3.3135e+00, -2.7741e+00, -5.7532e-01,  5.4133e-01,  8.3889e-01,\n",
      "         -1.7811e+00,  3.7789e+00, -1.5315e+00, -2.8482e+00, -3.6261e-01,\n",
      "          2.4106e+00, -1.6020e+00, -4.6415e+00, -3.0954e+00, -2.6732e+00,\n",
      "          6.0758e-01,  2.4386e+00, -2.9097e+00,  1.9316e+00,  1.4735e+00,\n",
      "          2.6580e+00,  7.0092e+00,  2.2599e+00,  3.8542e+00, -6.5881e-01,\n",
      "          2.2209e+00,  1.6223e-01,  1.5447e+00,  2.6382e-01,  5.4239e-01,\n",
      "         -1.4418e+00, -3.7262e+00,  2.1401e+00,  3.9427e-02, -1.4090e+00],\n",
      "        [ 1.1899e+01,  1.3112e+01,  1.7128e+00,  1.1413e+01,  5.0799e+00,\n",
      "          8.7185e+00,  4.0132e+00,  9.8929e+00,  8.0301e+00,  6.4318e+00,\n",
      "          6.0483e+00,  1.1176e+01,  3.4017e+00,  1.2644e+01,  8.3539e+00,\n",
      "          1.6656e+01,  3.1166e-01,  6.5729e+00,  2.7251e+00,  5.9987e+00,\n",
      "          7.5309e+00,  3.1713e+00,  1.1422e+01,  5.5608e-01,  6.3763e+00,\n",
      "          1.5745e+00,  6.5376e+00,  9.6452e+00,  1.2722e+00,  4.7744e+00,\n",
      "         -1.5024e-01,  9.6215e+00,  1.2382e+01,  2.7949e+00,  9.8538e+00,\n",
      "          1.1384e+01,  1.5758e+00,  1.0997e+01,  4.1928e+00,  1.0389e+01,\n",
      "          1.0796e+01,  6.2241e+00,  4.6840e+00,  5.9505e+00,  3.0650e+00,\n",
      "          7.6139e+00,  4.0632e+00,  4.3715e+00,  3.9373e+00,  6.5596e+00,\n",
      "          3.1391e+00,  5.1761e+00, -6.3594e-01, -1.7988e-01,  5.2480e+00,\n",
      "          6.3213e-01,  6.5476e+00,  3.2821e+00,  6.4152e-01,  1.4103e+00,\n",
      "          8.6773e+00,  8.2087e+00,  2.1856e+00,  2.7084e+00,  1.3617e+01,\n",
      "          1.7402e+00,  8.0697e+00,  6.1802e+00,  6.7211e+00,  2.0316e+00,\n",
      "          4.7756e+00,  8.0750e+00,  4.4863e+00,  2.2146e+00,  1.1510e+01,\n",
      "          1.3866e+00,  5.8523e+00,  7.0861e+00,  3.2478e+00,  4.7166e+00,\n",
      "          3.2913e+00,  6.7458e+00,  3.1225e+00,  3.2373e+00,  4.8537e+00,\n",
      "          4.9185e+00,  1.2300e+01,  6.4076e+00,  8.4408e+00,  9.9089e+00,\n",
      "          3.1942e+00,  3.2042e-01,  1.3520e+01,  3.2263e+00,  8.6423e-01,\n",
      "          1.1796e+01,  4.7467e+00,  1.1759e+01,  5.4405e+00,  3.0410e+00],\n",
      "        [ 1.2502e+00, -4.7731e+00, -2.2525e-01,  3.2246e+00,  5.6174e-02,\n",
      "          2.5347e+00,  2.2316e+00,  4.8889e+00, -1.0813e+00, -1.8492e+00,\n",
      "          1.6962e+00,  8.6069e+00, -6.2642e-01,  1.9389e+00,  6.0172e-02,\n",
      "         -7.1045e-01,  1.3460e+00,  2.2443e-01,  4.5534e+00,  2.2747e+00,\n",
      "         -1.1968e+00,  1.3512e+00, -1.3834e+00, -1.9700e+00,  2.4946e+00,\n",
      "          1.2195e+00,  4.0854e+00,  3.0449e+00, -1.9129e-02,  8.2276e-01,\n",
      "          7.9411e-01, -9.3651e-01, -3.0542e+00,  5.7411e-01,  1.6665e+00,\n",
      "          3.5301e+00,  2.4703e+00,  1.0011e+00, -2.5037e+00, -4.5256e+00,\n",
      "          8.4268e+00, -8.4329e-02,  1.1857e+00,  4.0430e+00, -8.1173e-01,\n",
      "          1.6516e+00,  1.2769e+00,  1.8085e+00, -1.1493e+00,  4.6180e+00,\n",
      "          5.3491e-01,  4.0282e+00,  5.5492e-01, -1.9608e+00, -2.3572e+00,\n",
      "          1.3404e+00,  2.5638e+00,  3.5575e+00, -6.8630e-01, -3.1985e+00,\n",
      "         -7.7642e-01, -1.9684e-01,  9.8791e-02,  1.3168e+00, -4.0487e+00,\n",
      "          8.5163e-01,  5.4402e+00,  1.6174e+00,  2.8668e+00,  8.7361e-01,\n",
      "          4.9053e+00, -2.2160e+00, -1.6943e+00,  2.1219e-01,  1.0051e+00,\n",
      "          2.4738e-01,  2.2998e+00, -6.5767e-01,  6.1355e+00,  3.5777e+00,\n",
      "          2.2493e+00, -1.4613e+00,  6.7902e-01,  1.2381e+00, -1.1320e+00,\n",
      "         -3.1910e+00,  1.5516e+00,  3.6447e+00, -1.5499e+00,  1.7221e+00,\n",
      "          1.7174e+00,  2.2834e+00, -1.2354e+00,  1.2892e+00, -2.2298e+00,\n",
      "          5.3156e+00,  5.7426e-01, -1.5691e-01,  1.5592e+00,  3.4548e+00],\n",
      "        [-6.4306e+00, -8.2423e+00, -4.3266e-01,  4.9903e-01, -1.8566e+00,\n",
      "         -2.5917e+00,  3.4032e-02, -7.3366e+00, -2.9209e+00, -1.2678e+00,\n",
      "         -1.3968e+00,  6.2205e-01, -3.3423e+00, -6.4466e+00, -3.2349e+00,\n",
      "         -6.2822e+00, -6.3114e-01, -2.3029e+00, -1.4645e+00, -2.6183e+00,\n",
      "         -9.0042e-01, -1.4193e+00, -8.0638e+00, -4.7623e-01, -2.8831e-01,\n",
      "         -3.5155e-01, -1.6693e+00, -2.4373e+00, -9.8567e-01, -1.5773e+00,\n",
      "         -1.0707e+00, -2.6793e+00, -5.4920e+00, -2.2662e+00, -2.8729e+00,\n",
      "         -5.0627e+00, -3.4511e-01, -3.4309e+00, -1.8029e+00, -7.8073e+00,\n",
      "         -1.1162e-01, -5.8423e+00,  4.4755e-01, -1.7279e+00, -3.1221e+00,\n",
      "         -5.0068e+00, -1.3319e+00, -5.7391e+00, -2.3284e+00,  6.2341e-01,\n",
      "         -2.4708e+00, -1.6425e+00, -2.0242e-01,  4.1539e-01, -1.8496e+00,\n",
      "         -2.7036e+00, -2.7114e+00, -1.9197e+00, -3.0304e-01, -6.5403e-01,\n",
      "         -1.3916e+00, -3.3090e+00, -1.3606e+00, -1.2286e+00, -2.2854e+00,\n",
      "         -3.5983e+00, -1.5978e-01, -6.0912e+00,  2.3355e+00, -4.4363e-01,\n",
      "         -2.7890e+00, -1.7890e+00, -4.7767e+00, -8.3179e-03, -4.4641e+00,\n",
      "          1.8055e+00, -3.3453e+00, -4.7732e+00, -1.0993e+00, -1.3251e+00,\n",
      "         -3.9024e-02, -4.5484e+00,  8.6798e-01, -2.5472e+00, -1.0077e+00,\n",
      "         -4.4057e+00, -6.7786e+00, -1.9883e+00, -3.9075e+00, -2.3859e+00,\n",
      "         -2.8558e+00, -2.7667e-01, -5.4988e+00, -1.0379e+00, -1.5565e-01,\n",
      "         -4.9826e+00, -1.2217e+00, -6.5315e+00, -1.0508e+00, -1.6583e+00],\n",
      "        [-4.8649e-01, -1.3458e+00,  3.5299e-01, -1.3676e+00,  3.9253e-02,\n",
      "          6.4157e-01, -1.2062e+00,  2.0377e+00, -2.4654e+00, -1.4003e+00,\n",
      "         -1.1318e-01, -4.5916e+00,  4.9712e-03, -6.3881e-01, -2.8101e+00,\n",
      "          3.5479e-01,  2.1115e-01, -1.3679e+00, -3.9778e-02,  4.1816e-01,\n",
      "          6.9083e-01, -7.5086e-01,  2.7432e-02,  5.2075e+00, -1.3556e-01,\n",
      "          4.2532e-02,  8.6846e-01,  3.0728e+00,  5.2658e+00,  1.7490e-01,\n",
      "          9.7052e-01,  1.1771e+00, -2.3368e-01, -4.2897e-01, -2.8623e-01,\n",
      "         -1.7238e+00,  5.2976e-01,  1.2398e+00, -9.7722e-01, -8.8454e-01,\n",
      "         -4.5895e+00, -5.9905e-02, -2.9088e+00,  1.5934e+00, -2.3955e+00,\n",
      "          2.4730e+00, -7.1123e-01,  3.3332e-01, -6.9698e-01,  4.0355e+00,\n",
      "         -2.8180e+00, -2.3808e+00,  1.4565e+00,  2.8760e-01,  2.6722e+00,\n",
      "          8.2096e-01,  1.0897e+00, -2.5458e-01,  8.1129e-01,  3.8955e+00,\n",
      "          9.8182e-01, -1.0939e+00,  3.3935e-01, -5.3047e-01, -1.3285e+00,\n",
      "         -2.0785e+00, -1.1229e+00,  1.1415e+00, -3.9535e+00,  2.0386e+00,\n",
      "          6.9337e-01,  3.8898e+00,  1.9544e-01, -1.6330e+00, -2.3179e+00,\n",
      "          7.3271e+00,  1.6192e+00, -1.3332e+00, -1.1353e+00,  5.5488e-01,\n",
      "          1.0409e+00, -6.0045e-01, -1.3694e+00,  3.5884e-01,  2.8747e+00,\n",
      "          8.3111e-01,  1.2384e+00, -2.2852e+00,  2.3886e+00, -9.3710e-01,\n",
      "         -1.6179e+00, -2.9593e-01, -1.9108e+00, -6.7917e-01,  1.4901e-01,\n",
      "         -3.2264e+00,  3.5461e+00, -9.4248e-01, -2.2847e+00, -4.1686e-01],\n",
      "        [ 2.1960e+00,  1.4167e+00,  4.9070e-01,  1.1291e+01,  2.0924e+00,\n",
      "          7.8741e+00,  1.4547e+00,  4.3946e+00,  3.7965e+00,  7.0793e+00,\n",
      "          2.6852e+00,  5.2756e+00,  3.4981e+00, -2.1634e+00,  1.0585e+00,\n",
      "          5.8109e+00, -2.6746e-01,  3.3810e+00,  2.5863e+00, -4.2765e-01,\n",
      "          7.4222e+00,  2.9387e+00,  6.8752e+00,  5.0892e+00,  2.2613e+00,\n",
      "          1.0287e+01, -4.5453e-01,  3.6173e+00,  6.1010e+00, -1.6007e+00,\n",
      "          3.3246e+00,  1.9988e-01, -8.9474e-01,  2.5193e+00,  5.4365e+00,\n",
      "          1.1082e+01,  1.9636e+00,  4.7144e+00,  5.9526e+00,  3.7818e+00,\n",
      "         -3.5659e+00,  1.1459e+00,  4.2498e+00,  1.4120e+01,  3.8913e+00,\n",
      "          9.4577e+00,  2.3166e+00,  8.3726e+00,  1.3693e-01,  1.4455e+01,\n",
      "          4.1984e+00, -2.9294e+00,  2.9963e+00,  4.3156e+00,  2.0078e+00,\n",
      "          3.2930e+00,  2.7488e+00,  9.6721e-01,  7.9550e-03,  3.0721e+00,\n",
      "          3.9037e+00,  9.6384e-02,  8.4464e-01,  1.3744e+00, -1.9018e+00,\n",
      "          3.5167e+00,  7.9191e+00,  3.5425e+00,  2.3824e+00,  2.2823e+00,\n",
      "          2.2511e+00,  2.1604e+00,  4.9062e-01,  4.6010e+00, -9.7631e-01,\n",
      "          3.5625e+00,  2.6529e+00,  5.3252e+00,  3.5173e+00,  5.9385e+00,\n",
      "          3.2033e+00,  1.3866e+00,  6.5400e+00, -7.5442e-01,  1.2708e+00,\n",
      "          5.6405e-01,  9.1615e-01, -1.9621e+00,  3.1992e+00,  4.2119e-02,\n",
      "          4.4809e+00,  5.4600e+00, -2.4554e-01,  4.8018e+00,  3.0892e+00,\n",
      "          9.6698e+00,  1.0023e+01,  1.3870e+00, -1.3788e+00,  7.3113e-01],\n",
      "        [-3.5885e+00, -1.2550e+01, -2.6351e+00, -8.9131e+00, -3.3313e+00,\n",
      "         -6.3416e+00, -3.3368e+00, -3.3814e+00, -8.0662e+00, -7.1652e+00,\n",
      "         -3.4382e+00, -3.7194e+00, -4.1849e+00, -5.8621e+00, -6.4624e+00,\n",
      "         -1.3996e+01,  7.4692e-01, -3.7526e+00, -1.8048e-01, -1.2316e+00,\n",
      "         -8.9756e+00, -5.7532e+00, -1.4791e+01, -2.5985e+00, -4.3353e+00,\n",
      "         -6.8125e+00, -2.4639e+00, -4.9418e+00, -1.9741e+00, -1.7089e+00,\n",
      "         -2.0598e-01, -6.4205e+00, -7.8774e+00, -3.8532e+00, -4.3134e+00,\n",
      "         -1.4183e+01, -8.8844e-02, -8.5800e+00, -8.9194e+00, -8.7302e+00,\n",
      "         -6.9004e-01, -2.3107e+00, -4.3727e+00, -6.8964e+00, -4.7989e+00,\n",
      "         -1.0387e+01, -3.1794e+00, -6.6446e+00, -3.6386e+00, -9.6491e+00,\n",
      "         -6.2051e+00,  3.3448e-01,  2.5105e-01, -2.9501e+00, -6.6225e+00,\n",
      "         -1.7706e+00, -1.3149e-01, -1.2122e-01, -6.1904e-01, -4.0126e+00,\n",
      "         -6.9533e+00, -4.8569e+00, -8.7801e-01, -1.8591e+00, -1.1356e+00,\n",
      "         -4.4230e+00, -5.9498e+00, -4.0627e+00, -4.3391e+00, -2.6377e-01,\n",
      "          3.3081e+00, -5.8316e+00, -1.0102e+00, -4.0811e+00, -4.6452e+00,\n",
      "         -1.0176e+00, -5.3066e+00, -5.0475e+00, -3.0651e-01, -3.2029e+00,\n",
      "         -1.7246e+00, -7.3334e+00, -3.8685e+00, -5.5878e-02, -1.7112e-01,\n",
      "         -5.0775e+00, -6.9541e+00,  1.1612e+00, -7.9821e+00, -6.7709e+00,\n",
      "         -5.2390e+00, -1.5689e+00, -6.3419e+00, -4.3744e+00, -2.6475e+00,\n",
      "         -4.5460e+00, -1.1150e+01, -8.1976e+00, -3.8600e+00, -5.0820e-01]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward() # this does not change the weights, but it computes gradients\n",
    "print(model.layer2.weight.grad) # after calling .backward() this is now populated (used to be \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0660, -0.0286, -0.0124, -0.0448, -0.0034,  0.0432, -0.0301,  0.0754,\n",
      "         0.0533,  0.0261], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.layer2.weight[0][0:10]) # the weights are still not changed, as can be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0642, -0.0303, -0.0116, -0.0478, -0.0033,  0.0421, -0.0307,  0.0764,\n",
      "         0.0559,  0.0276], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimiser.step() # performs a parameter update based on the current gradient stored in .grad attribute of a parameter and the update rule (which was set when the optimiser was initialised) - eg. with SGD\n",
    "\n",
    "# now it's very important to zero out the gradients\n",
    "optimiser.zero_grad() # this makes sure that the gradients don't accumulate through the different training batches\n",
    "print(model.layer2.weight[0][0:10]) # now the weights have been adjusted using the gradients calculated in the loss.backward() step and seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning off autograd momentarily can be done as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<MulBackward0>)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<MulBackward0>)\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, requires_grad=True) * 3\n",
    "b = torch.ones(2, 3, requires_grad=True) * 3\n",
    "\n",
    "with torch.no_grad():\n",
    "    c_no_grad = a + b \n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c_no_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning off autograd can also be done for functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@torch.no_grad()\n",
    "def add_tensors(x, y): # whatever happs here is detached form the computation history\n",
    "    return a + y\n",
    "\n",
    "add_tensors(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a copy of a tensor which has gradient tracking can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_no_gradient = a.detach() # this creates a copy that is detached form the computation history \n",
    "a_no_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't perform inplace operations on input tensors that require gradients, as it will destroy information.\n",
    "\n",
    "Inplace operations are operations that directly change the content of a given tensor, without making a copy.\n",
    "\n",
    "These typically end with _, eg. `torch.sin_()`.\n",
    "\n",
    "Not using implace operations is more efficient when not under heavy memory pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2618, 0.5236, 0.7854, 1.0472, 1.3090, 1.5708, 1.8326, 2.0944,\n",
       "        2.3562, 2.6180, 2.8798, 3.1416, 3.4034, 3.6652, 3.9270, 4.1888, 4.4506,\n",
       "        4.7124, 4.9742, 5.2360, 5.4978, 5.7596, 6.0214, 6.2832],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "a = torch.linspace(0., 2. * math.pi, steps=25, requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet01.ipynb Cell 27'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet01.ipynb#ch0000026?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49msin_(a)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "torch.sin_(a) # ERROR due to implace operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0272, -0.0054, -0.0126,  ..., -0.0038,  0.0103, -0.0054],\n",
      "        [ 0.0026,  0.0180, -0.0079,  ..., -0.0192,  0.0146,  0.0148],\n",
      "        [ 0.0155, -0.0087, -0.0229,  ..., -0.0122,  0.0173, -0.0291],\n",
      "        ...,\n",
      "        [ 0.0092, -0.0310, -0.0075,  ..., -0.0231, -0.0172, -0.0068],\n",
      "        [-0.0271,  0.0277,  0.0293,  ...,  0.0248, -0.0047, -0.0251],\n",
      "        [ 0.0117,  0.0121, -0.0144,  ...,  0.0296,  0.0088,  0.0260]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0085, -0.0075, -0.0230,  0.0027, -0.0216, -0.0169, -0.0099, -0.0133,\n",
      "         0.0239, -0.0014,  0.0275,  0.0286,  0.0041,  0.0048, -0.0020,  0.0200,\n",
      "        -0.0127, -0.0295, -0.0254, -0.0281, -0.0047, -0.0021, -0.0087, -0.0146,\n",
      "         0.0135,  0.0166, -0.0291, -0.0258,  0.0067,  0.0090, -0.0113,  0.0054,\n",
      "        -0.0001,  0.0213,  0.0251,  0.0279,  0.0144,  0.0123, -0.0284, -0.0014,\n",
      "        -0.0067,  0.0272,  0.0055,  0.0263,  0.0175,  0.0048, -0.0051,  0.0158,\n",
      "         0.0197,  0.0115, -0.0303, -0.0139, -0.0312,  0.0183, -0.0232,  0.0209,\n",
      "         0.0020,  0.0038, -0.0269, -0.0155,  0.0013, -0.0071, -0.0111, -0.0276,\n",
      "        -0.0269, -0.0030,  0.0108, -0.0079,  0.0184, -0.0057,  0.0237,  0.0229,\n",
      "         0.0024,  0.0217,  0.0171,  0.0118,  0.0035, -0.0010, -0.0241,  0.0242,\n",
      "        -0.0305, -0.0215,  0.0044, -0.0221,  0.0022, -0.0296,  0.0120,  0.0238,\n",
      "        -0.0155, -0.0010, -0.0282, -0.0215, -0.0209, -0.0233,  0.0134,  0.0228,\n",
      "        -0.0127, -0.0066, -0.0210, -0.0271], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-6.4235e-02, -3.0309e-02, -1.1622e-02, -4.7836e-02, -3.2642e-03,\n",
      "          4.2075e-02, -3.0723e-02,  7.6370e-02,  5.5899e-02,  2.7577e-02,\n",
      "          7.6917e-02, -2.8629e-02, -8.4661e-02, -3.0674e-02,  7.6718e-02,\n",
      "          5.8615e-02,  3.8390e-02, -6.0287e-02,  2.2090e-02,  1.0174e-01,\n",
      "          7.3557e-02, -4.7871e-02, -9.5088e-02, -4.8083e-02, -4.1917e-02,\n",
      "          2.2356e-02,  3.8099e-02, -7.2400e-02, -2.7279e-02,  2.9941e-02,\n",
      "         -7.8020e-02, -4.0392e-02,  4.3254e-02, -5.3299e-02,  2.7662e-02,\n",
      "          1.5720e-02,  9.4146e-02,  1.2285e-02,  7.1397e-04, -4.0673e-02,\n",
      "         -2.9764e-02,  6.0547e-02, -4.6872e-02, -9.3313e-02, -9.1777e-02,\n",
      "          4.9780e-02,  8.6408e-02, -5.7005e-03,  9.1670e-02, -8.6257e-02,\n",
      "          1.5394e-02,  8.4209e-02, -9.6018e-02, -8.9540e-02,  2.9374e-02,\n",
      "         -9.3878e-02, -8.2697e-02,  3.7470e-02, -5.3186e-02, -4.3548e-02,\n",
      "         -4.5074e-02, -8.3742e-02,  2.6612e-02,  6.7133e-02, -1.2212e-02,\n",
      "          6.7233e-02,  7.3897e-02, -5.2196e-02,  8.8590e-02,  1.9202e-03,\n",
      "          1.8649e-02,  9.4194e-02,  8.2221e-02, -1.3751e-02,  1.4925e-02,\n",
      "          3.2679e-02, -6.5646e-03, -7.4854e-02, -6.2495e-02,  9.5208e-02,\n",
      "         -6.9419e-02,  3.8382e-02,  8.7089e-02,  8.3507e-02, -3.1764e-02,\n",
      "         -1.6478e-02, -5.3297e-02,  7.7129e-02, -5.8956e-02,  5.3251e-02,\n",
      "         -3.3307e-02,  8.2467e-02, -7.2014e-02, -1.0061e-01,  9.1697e-02,\n",
      "         -2.7560e-02,  7.7155e-04, -4.4937e-03, -7.8435e-02, -4.4040e-02],\n",
      "        [-8.5938e-02,  5.3641e-02, -1.6980e-02, -7.5651e-02, -1.4716e-02,\n",
      "          1.2323e-02,  8.0744e-02, -5.3160e-03,  2.8779e-02, -3.7210e-02,\n",
      "         -3.3382e-02,  2.4807e-02,  6.4563e-02,  4.8677e-02,  2.9101e-02,\n",
      "          8.8200e-02, -3.3478e-02, -7.5892e-02,  5.7306e-03,  8.3145e-02,\n",
      "         -6.9074e-02, -4.8941e-02,  3.3696e-02,  3.0332e-02,  8.7946e-02,\n",
      "         -5.1562e-03, -9.2155e-03,  2.5201e-02,  7.5960e-02, -8.9675e-03,\n",
      "          6.0848e-02, -4.8608e-02,  7.3626e-02, -5.2201e-02,  7.9149e-02,\n",
      "         -5.6600e-02, -2.4320e-02,  1.1629e-03,  7.9616e-02,  5.8824e-02,\n",
      "         -2.8310e-02,  5.0539e-02, -4.8219e-02,  6.3490e-02,  5.6851e-02,\n",
      "          2.9416e-02,  4.1650e-02,  5.4856e-02, -8.3933e-02,  9.2532e-02,\n",
      "         -2.4545e-02,  5.3411e-03,  9.6041e-02,  3.3580e-02, -5.5060e-02,\n",
      "         -6.5267e-02, -2.4966e-02,  8.6664e-02, -3.5482e-02,  2.5786e-02,\n",
      "         -3.1175e-02, -8.4782e-02, -3.0612e-02, -7.9066e-02,  8.7004e-02,\n",
      "         -7.5975e-02, -3.0948e-02, -8.4799e-03,  1.5932e-02, -5.6829e-02,\n",
      "         -5.0775e-02, -8.9774e-02,  5.3556e-02, -9.8959e-02, -9.4474e-02,\n",
      "          4.3572e-02,  9.7658e-02,  3.1665e-02,  4.8700e-02, -9.7128e-02,\n",
      "         -4.2681e-02,  7.9638e-02,  1.7854e-02, -2.5202e-02,  9.5458e-02,\n",
      "         -8.4332e-02, -9.1931e-02,  2.5334e-02,  2.9390e-03,  4.1482e-02,\n",
      "          7.4357e-02, -4.9924e-02, -6.8763e-02,  4.4614e-02, -8.2257e-02,\n",
      "         -1.4939e-02,  4.8180e-02,  7.6412e-03, -5.5234e-02, -3.6310e-02],\n",
      "        [ 4.9968e-02, -4.5385e-02,  7.1243e-02, -3.3215e-02, -7.8483e-02,\n",
      "         -7.6245e-02, -4.0953e-02, -2.4019e-02, -3.2556e-02, -5.5108e-02,\n",
      "         -7.0324e-03,  6.3866e-02, -3.9804e-02,  5.6960e-03, -9.6125e-02,\n",
      "          4.7312e-02,  9.4706e-02,  9.8186e-02, -8.5666e-02, -7.7068e-02,\n",
      "          1.6810e-02,  7.3436e-02,  9.7542e-02, -1.8708e-02, -6.0547e-02,\n",
      "         -5.4349e-02,  4.9586e-02,  7.2759e-02,  6.3799e-02,  2.7530e-02,\n",
      "         -5.3350e-02,  8.2723e-03,  2.4282e-02, -5.2764e-02,  5.2449e-02,\n",
      "          8.4381e-02, -7.9545e-02,  4.9768e-02,  4.3707e-02,  5.6079e-02,\n",
      "         -8.2190e-02,  3.4708e-03, -6.4002e-02,  6.3107e-02, -3.3847e-02,\n",
      "         -2.4857e-02, -1.8697e-03,  9.4679e-02, -2.5465e-02, -7.1676e-02,\n",
      "          9.0574e-02,  3.7725e-02,  7.8035e-02, -6.3698e-02, -8.5398e-02,\n",
      "         -4.2980e-02, -5.2199e-02, -4.9437e-02, -8.9582e-02, -4.6450e-02,\n",
      "          1.7638e-02, -6.4730e-02, -1.0071e-01, -8.9323e-03,  8.3981e-02,\n",
      "          7.4203e-02, -7.3106e-02, -9.4536e-02, -2.1147e-02,  5.3122e-02,\n",
      "         -7.7771e-02,  9.0728e-02, -7.0649e-02,  8.8313e-02,  1.9857e-02,\n",
      "          7.2502e-02,  4.9935e-03, -4.4934e-02,  5.1176e-02,  3.4387e-03,\n",
      "          5.6434e-02,  1.5165e-02,  8.6372e-02,  5.0058e-02, -8.1730e-02,\n",
      "          4.0051e-02, -6.6415e-03, -8.1742e-02, -7.3445e-02,  8.1320e-02,\n",
      "         -3.2492e-02,  1.7240e-03, -9.2420e-02, -2.7848e-02,  4.6454e-02,\n",
      "         -1.4321e-02,  3.6425e-02, -7.1685e-02,  9.7145e-02,  2.2644e-02],\n",
      "        [-8.2546e-02, -3.7091e-02, -8.1149e-02,  6.6779e-02,  8.4723e-02,\n",
      "         -9.1348e-02, -5.4983e-02, -9.2180e-02, -3.2912e-03,  7.2131e-02,\n",
      "         -5.4409e-02, -2.9751e-02,  2.5870e-02,  3.1802e-02, -4.0557e-02,\n",
      "         -2.3422e-03, -2.9424e-02, -3.3894e-02, -3.9001e-02,  8.7312e-02,\n",
      "          9.8751e-02,  7.2249e-02,  3.6230e-02,  8.7946e-02, -6.8898e-02,\n",
      "         -4.7041e-02,  1.8613e-02,  7.9897e-02,  5.7635e-02, -3.9501e-02,\n",
      "          9.3920e-02, -1.0250e-02, -9.5112e-02,  9.8004e-02, -2.4343e-02,\n",
      "          8.7469e-02,  6.1821e-02,  6.1504e-02, -5.1100e-02,  7.9858e-02,\n",
      "         -8.7394e-02, -1.3063e-02, -2.8970e-02,  7.8970e-02,  3.6146e-02,\n",
      "         -9.5948e-03, -3.7950e-02,  6.0905e-02,  6.9200e-02, -4.0593e-02,\n",
      "          3.8739e-02, -3.5686e-02,  4.4065e-02, -7.6605e-02, -6.0520e-02,\n",
      "         -3.4485e-02, -3.6968e-02, -5.5590e-02,  5.9102e-02,  5.7156e-02,\n",
      "         -5.6679e-02, -4.2675e-02,  3.4932e-02, -8.7516e-02, -6.6045e-03,\n",
      "          5.3735e-02, -3.6955e-02,  8.5336e-02,  7.8538e-02, -5.6242e-02,\n",
      "         -3.9439e-02, -1.2083e-02, -9.5667e-02,  8.9129e-02,  4.6298e-02,\n",
      "          2.6316e-02, -3.7777e-02,  9.8117e-02, -7.5731e-02, -5.0197e-02,\n",
      "          3.8892e-02,  2.1712e-02, -4.8544e-02,  5.6214e-02,  6.5052e-02,\n",
      "          7.9978e-02,  1.9623e-03,  1.1386e-02,  1.0043e-02,  7.2157e-03,\n",
      "          2.1893e-05, -3.1940e-02,  5.3253e-02,  4.6926e-02, -7.0079e-02,\n",
      "          4.1140e-02, -7.4006e-02,  7.0059e-02, -3.7102e-02, -1.8350e-02],\n",
      "        [ 6.5875e-03,  2.3570e-02,  1.4721e-02,  6.1608e-02,  9.7718e-03,\n",
      "          5.7451e-02,  6.1560e-03,  6.8167e-02,  6.8970e-02,  6.0499e-02,\n",
      "         -8.8680e-02,  4.5429e-02,  4.5113e-02,  5.4851e-02, -9.8833e-02,\n",
      "          4.9270e-02,  6.8845e-02,  7.1131e-02,  6.0203e-02,  6.1751e-02,\n",
      "         -9.8793e-02,  8.7713e-02, -7.1436e-02, -9.6257e-02, -4.7085e-02,\n",
      "         -3.5437e-02,  4.7777e-02,  8.1155e-02, -3.9812e-02,  8.9486e-02,\n",
      "         -3.4982e-02, -1.8959e-02, -4.3088e-02,  2.6954e-03,  1.7877e-02,\n",
      "         -1.0182e-01,  1.9130e-02,  2.1720e-02,  5.0851e-02, -7.0507e-02,\n",
      "          5.8657e-02,  3.3589e-05,  7.2580e-02, -1.0255e-02,  7.1074e-02,\n",
      "         -9.2439e-02,  8.5088e-02,  2.4148e-03, -4.9646e-03, -4.2834e-02,\n",
      "          4.0488e-02, -2.7081e-02,  1.8371e-03, -6.9898e-02, -4.7056e-02,\n",
      "         -3.0639e-02, -1.0329e-02, -3.0605e-02, -5.9419e-02,  6.6638e-02,\n",
      "         -2.1030e-02, -5.7341e-02,  3.3299e-03,  7.3809e-02,  4.4216e-02,\n",
      "         -8.5808e-03,  7.1448e-02, -1.4008e-02, -7.6091e-02,  5.8416e-02,\n",
      "          8.9954e-02,  9.0578e-02,  4.5240e-02,  4.4253e-02,  7.8244e-02,\n",
      "         -6.1128e-02,  8.4831e-02,  3.7623e-02,  5.5243e-02, -8.4329e-03,\n",
      "          4.3354e-02,  2.2542e-02, -2.2423e-02,  3.5183e-02,  9.4071e-02,\n",
      "         -3.5307e-02,  1.3229e-02, -8.4444e-02,  3.6474e-02, -1.5396e-02,\n",
      "         -9.3856e-02, -7.7176e-03,  5.5215e-02,  6.9743e-04,  6.9121e-02,\n",
      "          7.7191e-02, -5.7343e-02, -9.6852e-03,  7.7119e-02,  6.6500e-02],\n",
      "        [-9.1603e-02, -6.8418e-02,  8.6203e-02, -4.4332e-02,  5.4663e-02,\n",
      "         -8.8285e-02, -3.6205e-03,  5.4538e-02,  5.7805e-02, -6.6631e-02,\n",
      "          1.3999e-02,  6.3708e-02,  9.7623e-02, -9.4068e-02, -8.9332e-02,\n",
      "          7.3440e-02, -5.0430e-02, -2.9574e-02,  7.0473e-02, -2.3457e-02,\n",
      "          3.1142e-02,  1.6451e-02,  4.2692e-02, -5.3238e-03, -7.2467e-02,\n",
      "         -5.8862e-02, -6.0144e-02,  5.9422e-02,  6.8808e-02, -7.0425e-02,\n",
      "         -7.9278e-02, -8.6225e-02, -8.8026e-02, -5.5860e-02,  5.8783e-02,\n",
      "          4.7664e-02,  7.7392e-02,  7.4733e-04,  2.5215e-03,  9.4936e-02,\n",
      "         -9.1448e-04,  7.0428e-02,  4.3233e-02, -9.1531e-02,  5.9833e-02,\n",
      "         -4.4296e-02,  1.1995e-02, -7.6865e-02, -9.0884e-03, -3.6103e-02,\n",
      "          1.7674e-02, -1.7275e-02,  4.3833e-02,  8.4825e-03,  6.8500e-02,\n",
      "          7.7096e-02, -9.6374e-02, -6.0434e-02, -1.2552e-02,  7.8344e-02,\n",
      "          2.7141e-02, -3.7032e-02, -2.8064e-03,  1.6091e-02, -6.0720e-02,\n",
      "         -6.4758e-02,  4.2815e-03, -5.9508e-02, -4.7928e-03,  5.0238e-02,\n",
      "          8.7891e-03, -8.5383e-02,  1.6650e-02,  8.1278e-02, -7.6122e-02,\n",
      "         -1.6677e-02, -3.6843e-02,  3.6305e-02,  5.7039e-02,  5.5890e-02,\n",
      "         -5.7494e-02, -4.9512e-03, -8.5847e-02, -4.0533e-02,  4.3332e-02,\n",
      "         -7.7495e-02, -6.4405e-02,  4.5129e-02, -2.4118e-03,  2.5402e-02,\n",
      "         -1.4908e-02, -3.5849e-02,  1.1450e-03,  8.9684e-02, -4.9009e-02,\n",
      "         -1.0463e-01, -8.8350e-02, -2.9827e-02, -4.8574e-02, -8.6276e-02],\n",
      "        [-4.1606e-02, -5.0150e-02, -7.9210e-02, -2.1365e-02,  1.7393e-02,\n",
      "          2.5109e-02,  3.9843e-02, -6.5890e-02,  8.2419e-02,  3.0659e-02,\n",
      "         -7.7019e-02,  2.5107e-02, -6.0893e-02,  4.5624e-02, -2.5090e-02,\n",
      "         -4.6224e-02,  7.6322e-02, -9.4497e-02,  2.1235e-04, -7.0289e-02,\n",
      "          2.6156e-02,  5.4147e-02, -4.8038e-02,  9.2349e-02, -8.2816e-02,\n",
      "          9.5733e-02, -7.0159e-03, -8.8258e-02,  3.5196e-02, -8.9242e-02,\n",
      "         -8.9669e-02, -5.4145e-02, -6.7102e-02, -9.5136e-02, -7.8224e-02,\n",
      "          2.9590e-02, -1.0694e-02,  1.6086e-02, -2.8619e-02, -8.2717e-02,\n",
      "         -9.7489e-02,  4.4934e-03,  5.1872e-02,  5.7361e-02, -5.7396e-02,\n",
      "         -6.3571e-02,  7.8642e-03,  7.8057e-02,  1.1320e-02, -1.0316e-02,\n",
      "          6.1534e-02,  7.7213e-02,  1.8349e-02, -9.1017e-02,  6.6416e-02,\n",
      "          3.1495e-02,  8.7679e-02,  6.3189e-02, -1.6403e-02, -5.5890e-02,\n",
      "         -4.2505e-02, -7.2810e-02,  7.7873e-02,  2.4885e-02,  4.0456e-03,\n",
      "          7.8889e-02, -2.0037e-02,  3.8658e-02,  5.9967e-02, -5.8846e-02,\n",
      "         -6.9805e-02, -3.3251e-02, -4.6330e-02, -6.0795e-02,  8.7384e-02,\n",
      "         -9.2787e-02, -1.6232e-02, -1.6058e-02, -5.6512e-02,  1.0054e-01,\n",
      "         -4.1761e-02, -8.8575e-02,  6.6720e-03, -2.4550e-03,  8.2192e-02,\n",
      "         -1.8911e-02, -2.1806e-03,  3.1774e-02,  1.0352e-01,  6.7209e-03,\n",
      "         -6.3796e-03,  3.2435e-02, -3.4488e-02,  4.0935e-02,  6.1552e-02,\n",
      "         -6.3926e-02,  3.8726e-02, -6.7687e-02,  4.6100e-02, -9.7650e-02],\n",
      "        [-1.1332e-03,  8.4788e-02, -1.3127e-02,  5.3738e-02,  7.2874e-02,\n",
      "         -5.2673e-02, -7.4428e-03, -4.6109e-02, -9.0492e-02,  6.7974e-02,\n",
      "         -5.6452e-02, -7.1134e-02, -4.6805e-02,  9.5672e-02,  2.8702e-02,\n",
      "         -9.4120e-02, -9.4930e-02, -2.1452e-02, -9.0979e-02,  4.0469e-02,\n",
      "          8.0235e-02, -2.4090e-03,  2.4108e-02,  4.5312e-02,  2.4244e-02,\n",
      "          6.4259e-03,  6.9273e-02,  4.8870e-02,  7.2532e-02, -6.3891e-02,\n",
      "         -4.3462e-02, -1.0116e-01,  6.5016e-03, -4.9415e-02, -8.7532e-02,\n",
      "          9.6900e-02, -4.1306e-02, -5.3571e-02,  4.8192e-02,  5.4292e-02,\n",
      "         -9.3115e-02,  6.1618e-02,  7.4582e-02, -4.7934e-02,  3.4941e-02,\n",
      "          6.8017e-02, -5.5672e-02,  4.2030e-02, -3.8629e-02, -2.6701e-03,\n",
      "          3.2871e-02,  7.4243e-02,  9.3161e-02, -7.1458e-02,  8.3997e-02,\n",
      "          7.2296e-02,  2.4742e-02, -2.3897e-02,  3.9548e-02, -3.9936e-02,\n",
      "         -9.5512e-02,  3.0684e-02,  4.4979e-02, -7.4683e-02, -9.7175e-02,\n",
      "          6.6497e-02,  7.1260e-02, -5.9635e-02, -5.0814e-02, -1.8819e-02,\n",
      "          5.8104e-02, -4.7229e-03,  9.5567e-02, -5.0040e-02,  9.4370e-02,\n",
      "         -9.0256e-02, -3.4445e-02,  7.5934e-02,  9.5071e-04, -7.9522e-02,\n",
      "          1.7595e-02, -6.5784e-02, -4.0366e-02,  1.4280e-02,  8.0700e-02,\n",
      "         -4.3835e-02,  1.8216e-02, -6.0210e-02, -6.2584e-02, -8.1152e-02,\n",
      "         -6.6983e-02,  7.9467e-02, -1.8296e-02, -6.4452e-02,  1.4089e-02,\n",
      "          3.7175e-03,  1.2538e-02, -8.3960e-03,  8.2332e-02,  5.1267e-02],\n",
      "        [-7.3851e-02, -8.5806e-02,  6.0303e-02, -5.1644e-02,  1.7533e-02,\n",
      "         -8.6196e-02,  1.6454e-02, -4.7273e-02, -4.4627e-02, -3.1335e-02,\n",
      "         -4.0487e-03,  2.0072e-02, -1.2865e-02, -7.6964e-02, -9.0215e-02,\n",
      "          2.4760e-02,  3.2704e-02,  8.3652e-02, -4.5382e-02,  8.5625e-03,\n",
      "          8.2655e-02, -7.4876e-02, -6.7148e-02,  9.4908e-03, -2.4802e-02,\n",
      "          8.4567e-02, -9.5701e-02,  2.4720e-02,  8.6177e-02,  1.6698e-02,\n",
      "          7.0443e-02,  8.6965e-02,  8.9990e-02, -2.4608e-02,  7.8453e-02,\n",
      "         -2.8848e-02,  3.3518e-02,  8.6350e-02,  5.0245e-02, -8.5988e-02,\n",
      "         -3.8110e-02,  3.5275e-02, -4.0311e-02, -4.4849e-02,  5.4144e-02,\n",
      "         -8.5611e-02, -1.2489e-02,  7.8781e-02, -1.3059e-02, -1.1121e-01,\n",
      "         -1.4678e-02,  2.2986e-02,  5.1906e-02,  8.9009e-02,  4.5415e-02,\n",
      "         -1.3185e-04, -4.0728e-02, -8.5798e-02, -1.2434e-02,  9.3072e-02,\n",
      "          2.0983e-02, -2.2372e-02, -2.7715e-02, -3.9519e-02, -3.9784e-02,\n",
      "         -8.9383e-02, -1.8846e-02,  6.5403e-02, -8.8178e-02,  9.3280e-02,\n",
      "          5.2754e-02,  4.8339e-02, -3.3439e-02,  7.5492e-02,  5.9568e-03,\n",
      "          9.3944e-02,  6.2197e-02,  2.2334e-02, -2.5675e-04,  1.2308e-02,\n",
      "         -5.4098e-02, -1.0536e-02,  7.2669e-02, -2.9234e-02,  9.0569e-02,\n",
      "          5.1952e-02, -2.6267e-02,  6.2075e-02,  2.3369e-02, -4.7226e-02,\n",
      "         -5.7417e-02, -5.3074e-02,  2.8732e-02, -5.1894e-02,  3.6561e-02,\n",
      "          6.9133e-02,  7.0669e-02,  1.3391e-02, -9.5336e-02, -5.3262e-02],\n",
      "        [-8.9132e-02, -2.3285e-02, -5.5827e-02,  8.7114e-04, -9.1077e-02,\n",
      "          6.3049e-02,  7.0361e-02, -7.4775e-02,  7.8449e-02, -3.1258e-02,\n",
      "          6.8258e-02,  4.8353e-02, -5.6622e-02, -4.5687e-02, -8.6888e-02,\n",
      "         -2.5801e-03,  8.6996e-02, -6.2073e-02, -4.7846e-02,  6.2089e-02,\n",
      "          2.7718e-02, -4.4105e-02, -4.2809e-02,  7.3731e-02, -7.1086e-02,\n",
      "         -4.9719e-02, -2.9133e-02, -5.1241e-02,  1.1200e-02,  7.3400e-02,\n",
      "         -3.9279e-02,  4.2405e-02, -7.0614e-02, -2.3764e-02,  2.6568e-02,\n",
      "         -7.1016e-02,  2.8540e-02, -7.8028e-02, -2.5212e-02,  8.8987e-02,\n",
      "         -6.4928e-02,  6.8951e-02,  4.2867e-02, -4.3612e-02, -8.9899e-02,\n",
      "         -6.6955e-02,  7.8463e-02, -3.6725e-02, -7.0946e-02, -8.6752e-03,\n",
      "          6.0562e-02, -3.1346e-02, -4.7792e-02,  5.3874e-02,  9.0551e-02,\n",
      "         -6.2148e-02,  5.9170e-03, -6.1815e-02,  5.6450e-02,  1.4624e-02,\n",
      "          1.2956e-03, -8.9975e-02, -6.0865e-02,  3.4343e-02,  4.5553e-02,\n",
      "          4.6508e-02,  6.9438e-02,  9.6542e-02, -5.6286e-02,  5.4547e-02,\n",
      "         -5.7480e-02, -4.0419e-02,  5.1616e-02,  6.6580e-02, -6.5846e-03,\n",
      "          3.8255e-02, -6.5844e-04, -8.5439e-02, -5.0222e-02, -2.1278e-02,\n",
      "         -7.1680e-02,  8.6159e-02,  2.4880e-02,  8.9460e-02,  5.1169e-02,\n",
      "          1.0383e-01,  4.4807e-02, -5.8270e-02, -1.6607e-02,  7.0121e-02,\n",
      "          1.5124e-02, -4.5338e-03, -1.6619e-03,  7.7438e-02, -3.0372e-02,\n",
      "         -6.4621e-02,  2.8443e-02,  3.8946e-02,  6.4180e-02, -3.8127e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0577, -0.0782,  0.0038, -0.0830, -0.1135,  0.0763,  0.0904,  0.0975,\n",
      "        -0.0057,  0.1157], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research needed for the autograd profiler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (100, 1)\n",
      "Y shape:  (100,)\n",
      "Y: [-5.55385928e+01 -1.06619847e+01  2.27574081e+01  1.01096129e+02\n",
      "  1.44337558e+02  3.32888330e+01  3.30152710e+01 -2.58869694e+01\n",
      " -9.96391397e+01  2.38030714e+01 -4.55886864e+01 -8.33875709e+00\n",
      " -9.53154191e+01  3.64072963e+01 -8.72926036e+01  6.76693724e+01\n",
      " -1.36866100e+01 -5.54414224e+01 -6.53402399e+01 -5.44497141e+01\n",
      " -2.88351332e+01  1.78835048e+02  6.50839520e+01  2.66683131e+01\n",
      " -1.85459706e+01 -4.14990408e+01  8.55827764e-01  4.45616521e+01\n",
      "  1.15984811e+02 -6.46197993e+01 -2.59312718e+01 -6.08820426e+01\n",
      "  1.87195482e+01  7.50696998e+01  1.17203175e+02 -2.26982690e+01\n",
      " -5.63625811e+01  1.80837188e+02 -1.92574950e+02  6.85032358e+01\n",
      "  1.65522025e+02  1.05000391e+02 -7.04338757e+01 -5.87693362e+01\n",
      " -4.15757142e+01  7.32472269e+01  4.09664082e+01  8.04619460e+01\n",
      " -2.87939943e+01  3.42341054e+01 -4.17148764e+01  1.43547375e+01\n",
      "  7.93363240e+01  2.71292073e+01 -3.94873551e+01  6.68052070e+01\n",
      "  9.55308437e+01  3.56104075e+00  1.08568943e-01  5.64952893e+01\n",
      "  5.15753413e+01 -2.09741113e+00 -2.66559439e+01  3.97419819e+01\n",
      "  3.61014055e+01 -7.56019440e+01  1.97126065e+01 -7.16010331e+01\n",
      " -1.99035774e+01 -7.67084296e+01 -1.18338274e+02 -2.98246083e+01\n",
      "  1.51082783e+02  5.29226489e+01 -5.95516769e+01  3.07214747e+01\n",
      " -2.93550664e+01 -4.47861678e+01  1.00058362e+02  1.50576548e+02\n",
      "  1.22000422e+02 -1.81857166e+02  3.47392430e+00 -2.29801423e+01\n",
      "  4.51842772e+01  9.86063300e+01 -9.27788339e+00 -5.24778810e+01\n",
      "  3.85928318e+01 -1.99972423e+02 -9.52014653e+00 -3.47236288e+00\n",
      " -3.53122497e+01  7.54057582e+01  1.75701411e+01 -2.39600185e+01\n",
      "  1.32085955e+02  2.06075830e+01  5.11112097e+01 -2.63060397e+01]\n"
     ]
    }
   ],
   "source": [
    "X_numpy, Y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "print(\"X shape: \", X_numpy.shape)\n",
    "#print(\"X:\" , X_numpy)\n",
    "print(\"Y shape: \", Y_numpy.shape)\n",
    "print(\"Y:\", Y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9478],\n",
       "        [3.2474],\n",
       "        [3.3238]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [i for i in range(10)]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
