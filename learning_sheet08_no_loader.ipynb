{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cityscapes - Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import adabound # https://github.com/Luolc/AdaBound\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import imageio\n",
    "\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# For notificaiton\n",
    "#import AppKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device chosen GPU: NVIDIA TITAN RTX\n",
      "<built-in method size of Tensor object at 0x7f729ac8ab30>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Device chosen GPU:\", torch.cuda.get_device_name(device))\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 25\n",
    "batch_size = 256\n",
    "learning_rate = 0.00001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "log_directory = f\"runs/Cityscapes/resnet101/v0.0.0 Adam lr = {learning_rate}, epochs = {num_epochs}, batchsize ={batch_size}\"\n",
    "writer1  = SummaryWriter(log_directory)\n",
    "#writer2 = SummaryWriter(log_directory)\n",
    "\n",
    "# Loading dataset\n",
    "# Since the dataset is in PIL (Python Imaging Library) form, tranform them into tensors of normalised range [-1, 1]\n",
    "# transform = transforms.Compose( # this transforms.compose combines multiple tranformations as one\n",
    "#     [\n",
    "#         transforms.ToTensor(), \n",
    "#         #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "pil_to_tensor = transforms.Compose(\n",
    "    [ # https://colab.research.google.com/github/CSAILVision/semantic-segmentation-pytorch/blob/master/notebooks/DemoSegmenter.ipynb#scrollTo=-BvRk8ONb00G\n",
    "        #lambda x: np.array(x),\n",
    "        transforms.ToTensor(),\n",
    "    # transforms.Normalize(\n",
    "    #     mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
    "    #     std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The Cityscapes tataset is avaliable in PyTorch\n",
    "train_dataset = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='train', mode='fine', target_type='semantic', transform=pil_to_tensor, target_transform=transforms.ToTensor())\n",
    "test_dataset  = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='test',  mode='fine', target_type='semantic', transform=pil_to_tensor, target_transform=transforms.ToTensor())\n",
    "val_dataset   = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='val',   mode='fine', target_type='semantic', transform=pil_to_tensor, target_transform=transforms.ToTensor())\n",
    "\n",
    "workers = 5\n",
    "# Splitting the training and testing datasets into smaller batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,  pin_memory=True)#, num_workers=workers)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False, pin_memory=True)#, num_workers=workers)\n",
    "\n",
    "#classes = ('Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
    "\n",
    "# Checking a data sample \n",
    "# example = iter(test_loader)\n",
    "# images, labels = example.next()\n",
    "\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5  # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "print(train_dataset[0][0].size) # first index is the image, the second index is the first index's true segmentation\n",
    "#train_dataset[0][0]\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(24, 16))\n",
    "ax[0].imshow(train_dataset[7][0].numpy().transpose(1,2,0)) \n",
    "ax[1].imshow(train_dataset[7][1].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m#print(train_loader.dataset)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39m#print(test_loader.dataset)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39m#train_loader.batch_sampler.sampler\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=13'>14</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39m#train_dataset[0][0].shape\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=15'>16</a>\u001b[0m image, target \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(image[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000003?line=17'>18</a>\u001b[0m image\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#print(train_loader.dataset)\n",
    "#print(test_loader.dataset)\n",
    "#train_loader.batch_sampler.sampler\n",
    "# train_batch_iterator = iter(train_loader.batch_sampler.sampler)\n",
    "# image, label = train_batch_iterator.next()\n",
    "\n",
    "# for image, label in train_dataset:\n",
    "#     plt.imshow(to_pil_image(image))\n",
    "#     plt.show()\n",
    "\n",
    "# for image, label in train_loader:\n",
    "#     plt.imshow(to_pil_image(image[0]))\n",
    "#     plt.show()\n",
    "\n",
    "#train_dataset[0][0].shape\n",
    "\n",
    "batch_iterator = iter(train_loader)\n",
    "current_batch = next(batch_iterator)\n",
    "\n",
    "image, target = current_batch\n",
    "plt.imshow(image[1].numpy().transpose(1,2,0))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loading a model\n",
    "model = torchvision.models.resnet101(pretrained=True).train().to(device)\n",
    "\n",
    "#num_features = model.features     # Getting the number of features going into the fully connected layer\n",
    "\n",
    "# Finetuning\n",
    "for param in model.parameters():    # Freezing/unfreezing the starting layers\n",
    "    # param.requires_grad = False\n",
    "    param.requires_grad = True\n",
    "\n",
    "#model.fc = nn.Linear(len(num_features), 10)  # Redefining the layer with the same input features, but new output features (the amount of classes that we need to classify)\n",
    "#model.to(device)\n",
    "\n",
    "#summary(model, (3, 32, 32))\n",
    "\n",
    "# IOU criterion from https://www.kaggle.com/code/iezepov/fast-iou-scoring-metric-in-pytorch-and-numpy/script\n",
    "SMOOTH = 1e-6\n",
    "def iou(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = iou_criterion\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08) # Comment this if a model is loaded\n",
    "\n",
    "n_total_steps = len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size   :  2975\n",
      "Test Size    :  1525\n",
      "Val Size     :  500\n"
     ]
    }
   ],
   "source": [
    "print('Train Size   : ', len(train_dataset))\n",
    "print('Test Size    : ', len(test_dataset))\n",
    "print('Val Size     : ', len(val_dataset))\n",
    "#summary(model, (3, 2048, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, image \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000017?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=168'>169</a>\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=170'>171</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=172'>173</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=173'>174</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=168'>169</a>\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=170'>171</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=172'>173</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=173'>174</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:180\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=175'>176</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=176'>177</a>\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=177'>178</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=179'>180</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(train_loader):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000006?line=22'>23</a>\u001b[0m testing_batches \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(test_loader) \u001b[39m# Every epoch tests the whole dataset once\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000006?line=24'>25</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000006?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m images_and_labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000006?line=27'>28</a>\u001b[0m     images \u001b[39m=\u001b[39m images_and_labels[i][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevork/MDI-Computer-Vision/learning_sheet08_no_loader.ipynb#ch0000006?line=28'>29</a>\u001b[0m     labels \u001b[39m=\u001b[39m images_and_labels[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=168'>169</a>\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=170'>171</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=172'>173</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=173'>174</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=168'>169</a>\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=170'>171</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=172'>173</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=173'>174</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:180\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=175'>176</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=176'>177</a>\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=177'>178</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> <a href='file:///home/kevork/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=179'>180</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Tensorboard\n",
    "#writer1.add_graph(model, images)\n",
    "#writer1.close()\n",
    "\n",
    "# Doing the training now\n",
    "\n",
    "running_loss = 0\n",
    "running_correct = 0\n",
    "#running_loss_test = 0\n",
    "\n",
    "steps_until_print = batch_size\n",
    "#print(f'One batch has {len(example)/batch_size} images\\nPrint every {steps_until_print}')\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # Check for stop - read file for boolean to stopping safely\n",
    "    train_json = open(\"train.json\")\n",
    "    train_dict = json.load(train_json)\n",
    "    if train_dict[\"train\"] == \"False\": break\n",
    "    \n",
    "    testing_batches = iter(test_loader) # Every epoch tests the whole dataset once\n",
    "\n",
    "    i = 0\n",
    "    for images_and_labels in train_loader:\n",
    "        \n",
    "        images = images_and_labels[i][0].to(device)\n",
    "        labels = images_and_labels[i][1].to(device)\n",
    "        # images = images.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimiser.zero_grad()   # Clear old gradient values\n",
    "        loss.backward()         # Calculate the gradients\n",
    "        optimiser.step()        # Update the model's weights (these are the model parameters(), different from hyperparameters)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add loss to the running loss \n",
    "            running_loss = loss.item()\n",
    "            _, predictions = torch.max(outputs, 1)                  # Evaluate along the 1st dimension\n",
    "\n",
    "            #running_correct = (predictions == labels).sum().item()  # We can call .item() as it's a tensor with one item\n",
    "\n",
    "            if (i+1) % 1 == 0: # Maybe replace 1 with steps_until_print\n",
    "                # Logging the loss\n",
    "                writer1.add_scalar('Loss/training', running_loss/steps_until_print, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "                # Adding the accuracy\n",
    "                #writer1.add_scalar('Accuracy/training', running_correct/batch_size*100, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "            # If for every 5 batches, test one batch. (test:train data ratio is split 1:5)\n",
    "            if (i+1) % 5 == 0:  # Logging the testing loss\n",
    "                test_images, test_labels = testing_batches.next()\n",
    "                \n",
    "                test_images = test_images.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "\n",
    "                test_outputs = model(test_images)\n",
    "\n",
    "                # _, test_predictions = torch.max(test_outputs, 1)\n",
    "                # test_running_correct = (test_predictions == test_labels).sum().item()\n",
    "                # writer1.add_scalar('Accuracy/testing', test_running_correct/batch_size*100, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "                test_loss = criterion(test_outputs, test_labels)\n",
    "                test_running_loss = test_loss.item()\n",
    "                writer1.add_scalar('Loss/testing', test_running_loss/len(test_labels), epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step\n",
    "        i += 1\n",
    "\n",
    "    #writer2.add_scalar('Loss/training', running_loss/steps_until_print, epoch * n_total_steps) # label of the scalar, actual loss mean, current global step\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.5f}')\n",
    "    #print(f'Finished epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "print(\"Training is done\")\n",
    "#AppKit.NSBeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1209\n",
      "['features.conv0.weight', 'features.norm0.weight', 'features.norm0.bias', 'features.norm0.running_mean', 'features.norm0.running_var', 'features.norm0.num_batches_tracked', 'features.denseblock1.denselayer1.norm1.weight', 'features.denseblock1.denselayer1.norm1.bias', 'features.denseblock1.denselayer1.norm1.running_mean', 'features.denseblock1.denselayer1.norm1.running_var']\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "# checkpoint = {\n",
    "#     \"epoch\": 90,\n",
    "#     \"model_state\": model.state_dict(),\n",
    "#     \"optimiser_state\": optimiser.state_dict()\n",
    "# }\n",
    "# torch.save(checkpoint, \"___checkpoint_densenet201_83p_cifar.pth\")\n",
    "print(len(model.state_dict().keys()))\n",
    "keys = list(model.state_dict().keys())\n",
    "print(keys[0:10])\n",
    "#print(optimiser.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DenseNet:\n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=5'>6</a>\u001b[0m epoch \u001b[39m=\u001b[39m loaded_checkpoint[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=7'>8</a>\u001b[0m \u001b[39m# for param in model.parameters():    # Freezing the startign layers\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=8'>9</a>\u001b[0m \u001b[39m#     # param.requires_grad = False\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=9'>10</a>\u001b[0m \u001b[39m#     param.requires_grad = False\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(loaded_checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_state\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet07.ipynb#ch0000006?line=12'>13</a>\u001b[0m optimiser\u001b[39m.\u001b[39mload_state_dict(loaded_checkpoint[\u001b[39m\"\u001b[39m\u001b[39moptimiser_state\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1476'>1477</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1477'>1478</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1478'>1479</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1480'>1481</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1481'>1482</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1482'>1483</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1483'>1484</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DenseNet:\n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". "
     ]
    }
   ],
   "source": [
    "# Loading the saved model\n",
    "model = torchvision.models.densenet201(pretrained=False)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08)\n",
    "\n",
    "loaded_checkpoint = torch.load(\"___checkpoint_densenet201_83p_cifar.pth\")\n",
    "epoch = loaded_checkpoint[\"epoch\"]\n",
    "\n",
    "# for param in model.parameters():    # Freezing the startign layers\n",
    "#     # param.requires_grad = False\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.load_state_dict(loaded_checkpoint[\"model_state\"])\n",
    "optimiser.load_state_dict(loaded_checkpoint[\"optimiser_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking after epoch POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training after epoch POC\n",
    "import json\n",
    "import time\n",
    "keep_training = True\n",
    "while(keep_training):\n",
    "    # Opening json \n",
    "    train_json = open(\"train.json\")\n",
    "    train_dict = json.load(train_json)\n",
    "    # Interpret \"train\" value as boolean\n",
    "    keep_training = False if train_dict[\"train\"] == \"False\" else True\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of previous line\n",
    "import json\n",
    "\n",
    "keep_training = True\n",
    "while(keep_training):\n",
    "    # Opening json \n",
    "    train_json = open(\"train.json\")\n",
    "    train_dict = json.load(train_json)\n",
    "    # Interpret \"train\" value as boolean\n",
    "    keep_training = False if train_dict[\"train\"] == \"False\" else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final implementation\n",
    "import json\n",
    "import time\n",
    "keep_training = True\n",
    "for a in range(0, 120):\n",
    "    # Opening json \n",
    "    train_json = open(\"train.json\")\n",
    "    train_dict = json.load(train_json)\n",
    "    if train_dict[\"train\"] == \"False\": break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
