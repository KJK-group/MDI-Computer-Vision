{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying hand written digits from the MNIST database\n",
    "- Main [source](https://youtu.be/c36lUUr864M?t=10360) that was used for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/mnist\")\n",
    "\n",
    "# For notificaiton\n",
    "import AppKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Setting the computing device to be the GPU if possible\n",
    "# My current laptop doesn't have cuda, but if it would be avalibale\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Since the images are 28x28 pixels in dimentions, the network's input size will\n",
    "# be 784 as we want it to be a flattened one dimentional array\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 40\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Getting the MNIST images as tensors by giving the transform function\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnistDataset', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset  = torchvision.datasets.MNIST(root='./mnistDataset', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "\n",
    "# Seperating the data into batches using the DataLoader utility. Shuffling is good for training, but doesn't matter for evaluation\n",
    "train_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Making a batch iterator\n",
    "examples = iter(train_loader)\n",
    "\n",
    "# Unpacking the training data batches \n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining the output `[100, 1, 28, 28]` above \n",
    "- 100 = the samples in one batch\n",
    "- 1   = one color channel - only brightness, no color channels abaliable\n",
    "- 28  = pixel dimention on first axis\n",
    "- 28  = pixel dimention on second axis\n",
    "\n",
    "The second output of `[100]` is simply a vector of labels, to each of the 100 samples in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting some example data\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)                   # Two rows, by three columns, in the index i+1\n",
    "    plt.imshow(samples[i][0], cmap='gray')  # Sample i, of the 0 (the first) channel\n",
    "\n",
    "#plt.show() # This is for plotting, but now we want to add the images to tensorboard\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close() # Flushes outputs\n",
    "#sys.exit() # Stops execution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, step 50/157, loss = 0.81294\n",
      "Epoch 1/40, step 100/157, loss = 0.32256\n",
      "Epoch 1/40, step 150/157, loss = 0.39478\n",
      "Epoch 2/40, step 50/157, loss = 0.26534\n",
      "Epoch 2/40, step 100/157, loss = 0.30062\n",
      "Epoch 2/40, step 150/157, loss = 0.31517\n",
      "Epoch 3/40, step 50/157, loss = 0.35888\n",
      "Epoch 3/40, step 100/157, loss = 0.20985\n",
      "Epoch 3/40, step 150/157, loss = 0.34576\n",
      "Epoch 4/40, step 50/157, loss = 0.34063\n",
      "Epoch 4/40, step 100/157, loss = 0.18805\n",
      "Epoch 4/40, step 150/157, loss = 0.14642\n",
      "Epoch 5/40, step 50/157, loss = 0.08368\n",
      "Epoch 5/40, step 100/157, loss = 0.17167\n",
      "Epoch 5/40, step 150/157, loss = 0.15094\n",
      "Epoch 6/40, step 50/157, loss = 0.27920\n",
      "Epoch 6/40, step 100/157, loss = 0.32909\n",
      "Epoch 6/40, step 150/157, loss = 0.15429\n",
      "Epoch 7/40, step 50/157, loss = 0.34909\n",
      "Epoch 7/40, step 100/157, loss = 0.17230\n",
      "Epoch 7/40, step 150/157, loss = 0.19512\n",
      "Epoch 8/40, step 50/157, loss = 0.25660\n",
      "Epoch 8/40, step 100/157, loss = 0.02877\n",
      "Epoch 8/40, step 150/157, loss = 0.05032\n",
      "Epoch 9/40, step 50/157, loss = 0.08669\n",
      "Epoch 9/40, step 100/157, loss = 0.11663\n",
      "Epoch 9/40, step 150/157, loss = 0.13944\n",
      "Epoch 10/40, step 50/157, loss = 0.06734\n",
      "Epoch 10/40, step 100/157, loss = 0.11772\n",
      "Epoch 10/40, step 150/157, loss = 0.09630\n",
      "Epoch 11/40, step 50/157, loss = 0.05420\n",
      "Epoch 11/40, step 100/157, loss = 0.03262\n",
      "Epoch 11/40, step 150/157, loss = 0.14164\n",
      "Epoch 12/40, step 50/157, loss = 0.19264\n",
      "Epoch 12/40, step 100/157, loss = 0.04656\n",
      "Epoch 12/40, step 150/157, loss = 0.06977\n",
      "Epoch 13/40, step 50/157, loss = 0.04869\n",
      "Epoch 13/40, step 100/157, loss = 0.06538\n",
      "Epoch 13/40, step 150/157, loss = 0.07237\n",
      "Epoch 14/40, step 50/157, loss = 0.07059\n",
      "Epoch 14/40, step 100/157, loss = 0.03147\n",
      "Epoch 14/40, step 150/157, loss = 0.02012\n",
      "Epoch 15/40, step 50/157, loss = 0.05126\n",
      "Epoch 15/40, step 100/157, loss = 0.03476\n",
      "Epoch 15/40, step 150/157, loss = 0.07094\n",
      "Epoch 16/40, step 50/157, loss = 0.02298\n",
      "Epoch 16/40, step 100/157, loss = 0.02242\n",
      "Epoch 16/40, step 150/157, loss = 0.06826\n",
      "Epoch 17/40, step 50/157, loss = 0.02027\n",
      "Epoch 17/40, step 100/157, loss = 0.01971\n",
      "Epoch 17/40, step 150/157, loss = 0.05852\n",
      "Epoch 18/40, step 50/157, loss = 0.02601\n",
      "Epoch 18/40, step 100/157, loss = 0.03556\n",
      "Epoch 18/40, step 150/157, loss = 0.04168\n",
      "Epoch 19/40, step 50/157, loss = 0.05562\n",
      "Epoch 19/40, step 100/157, loss = 0.04744\n",
      "Epoch 19/40, step 150/157, loss = 0.05085\n",
      "Epoch 20/40, step 50/157, loss = 0.01079\n",
      "Epoch 20/40, step 100/157, loss = 0.02108\n",
      "Epoch 20/40, step 150/157, loss = 0.02184\n",
      "Epoch 21/40, step 50/157, loss = 0.01108\n",
      "Epoch 21/40, step 100/157, loss = 0.03627\n",
      "Epoch 21/40, step 150/157, loss = 0.01462\n",
      "Epoch 22/40, step 50/157, loss = 0.01279\n",
      "Epoch 22/40, step 100/157, loss = 0.01801\n",
      "Epoch 22/40, step 150/157, loss = 0.01127\n",
      "Epoch 23/40, step 50/157, loss = 0.00763\n",
      "Epoch 23/40, step 100/157, loss = 0.01762\n",
      "Epoch 23/40, step 150/157, loss = 0.01062\n",
      "Epoch 24/40, step 50/157, loss = 0.01237\n",
      "Epoch 24/40, step 100/157, loss = 0.00608\n",
      "Epoch 24/40, step 150/157, loss = 0.01889\n",
      "Epoch 25/40, step 50/157, loss = 0.00914\n",
      "Epoch 25/40, step 100/157, loss = 0.00572\n",
      "Epoch 25/40, step 150/157, loss = 0.01929\n",
      "Epoch 26/40, step 50/157, loss = 0.01157\n",
      "Epoch 26/40, step 100/157, loss = 0.01273\n",
      "Epoch 26/40, step 150/157, loss = 0.00937\n",
      "Epoch 27/40, step 50/157, loss = 0.00572\n",
      "Epoch 27/40, step 100/157, loss = 0.00889\n",
      "Epoch 27/40, step 150/157, loss = 0.01566\n",
      "Epoch 28/40, step 50/157, loss = 0.00873\n",
      "Epoch 28/40, step 100/157, loss = 0.01652\n",
      "Epoch 28/40, step 150/157, loss = 0.00744\n",
      "Epoch 29/40, step 50/157, loss = 0.00990\n",
      "Epoch 29/40, step 100/157, loss = 0.01613\n",
      "Epoch 29/40, step 150/157, loss = 0.00360\n",
      "Epoch 30/40, step 50/157, loss = 0.00950\n",
      "Epoch 30/40, step 100/157, loss = 0.00536\n",
      "Epoch 30/40, step 150/157, loss = 0.00994\n",
      "Epoch 31/40, step 50/157, loss = 0.00489\n",
      "Epoch 31/40, step 100/157, loss = 0.00768\n",
      "Epoch 31/40, step 150/157, loss = 0.00199\n",
      "Epoch 32/40, step 50/157, loss = 0.00285\n",
      "Epoch 32/40, step 100/157, loss = 0.00611\n",
      "Epoch 32/40, step 150/157, loss = 0.00155\n",
      "Epoch 33/40, step 50/157, loss = 0.00803\n",
      "Epoch 33/40, step 100/157, loss = 0.00553\n",
      "Epoch 33/40, step 150/157, loss = 0.00185\n",
      "Epoch 34/40, step 50/157, loss = 0.00528\n",
      "Epoch 34/40, step 100/157, loss = 0.00621\n",
      "Epoch 34/40, step 150/157, loss = 0.00395\n",
      "Epoch 35/40, step 50/157, loss = 0.00096\n",
      "Epoch 35/40, step 100/157, loss = 0.00259\n",
      "Epoch 35/40, step 150/157, loss = 0.00611\n",
      "Epoch 36/40, step 50/157, loss = 0.00302\n",
      "Epoch 36/40, step 100/157, loss = 0.00588\n",
      "Epoch 36/40, step 150/157, loss = 0.00559\n",
      "Epoch 37/40, step 50/157, loss = 0.00371\n",
      "Epoch 37/40, step 100/157, loss = 0.00084\n",
      "Epoch 37/40, step 150/157, loss = 0.00106\n",
      "Epoch 38/40, step 50/157, loss = 0.00142\n",
      "Epoch 38/40, step 100/157, loss = 0.00205\n",
      "Epoch 38/40, step 150/157, loss = 0.00539\n",
      "Epoch 39/40, step 50/157, loss = 0.00237\n",
      "Epoch 39/40, step 100/157, loss = 0.00301\n",
      "Epoch 39/40, step 150/157, loss = 0.00294\n",
      "Epoch 40/40, step 50/157, loss = 0.00188\n",
      "Epoch 40/40, step 100/157, loss = 0.00156\n",
      "Epoch 40/40, step 150/157, loss = 0.00505\n",
      "Training is done\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes): # num_classes is the output size\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu   = nn.ReLU() # Activation function\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        # Since this is a multi class classificaiton problem, we're going to use nn.CrossEntropyLoss() below\n",
    "        # which itself implements Softmax.\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# The Adam optimiser is basically a better version of Stochastic Gradient Decent - need more research\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate) #  model.parameters() are the weights\n",
    "\n",
    "# Wiriting to tensorboard\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28))\n",
    "writer.close()\n",
    "\n",
    "# As we now have the loss and optimiser, we can start doing the training loop\n",
    "\n",
    "# Training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "running_loss = 0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs): # Looping through the epochs\n",
    "    for i, (images, labels) in enumerate(train_loader): # Looping through the batches\n",
    "        # The batch in train_loader is currently [100, 1, 28, 28]\n",
    "        # We want images tensor to be [100, 784], as there are 100 samples and each one have 784 values (28x28 flattened)\n",
    "        images = images.reshape(-1, 28*28).to(device) # \"-1 for first dimention, so tensor can find it out automatically\"\n",
    "        labels = labels.to(device)\n",
    "        # .to(device) pushes the tensor to the GPU if it's avalaible\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimiser.zero_grad()   # Making sure we're not accumulating the gradients\n",
    "        loss.backward()         # Calculating the new gradients\n",
    "        optimiser.step()        # This updates the gradients in the .parameters\n",
    "\n",
    "        # Add loss to the running loss \n",
    "        running_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, 1) # evaluate along the dimension 1\n",
    "        running_correct += (predictions == labels).sum().item() # we can call .item() as it's a tensor with one item\n",
    "\n",
    "\n",
    "        # Printing the loss\n",
    "        steps_until_print = 50\n",
    "        if (i+1) % steps_until_print == 0: # This prints every 10 steps\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.5f}')\n",
    "            # Let's add the mean vlaue to tensorboard\n",
    "            writer.add_scalar('Training loss', running_loss/steps_until_print, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "            # Adding the accuracy\n",
    "            writer.add_scalar('Accuracy', running_correct/steps_until_print, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "print(\"Training is done\")\n",
    "#AppKit.NSBeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "# Testing and evaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader: \n",
    "        # Data handling is a little simmilar to the beginning of the training loop\n",
    "        images = images.reshape(-1, 28*28).to(device) # \"-1 for first dimension, so tensor can find it out automatically\"\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # torch.max returns a touple of (value, index), though we don't need\n",
    "        # the values here, only the index, which corresponds to the classes\n",
    "        _, predictions = torch.max(outputs, 1) # evaluate along the dimension 1\n",
    "        n_samples += labels.shape[0] # This returns the number of samples in the current batch \n",
    "        n_correct += (predictions == labels).sum().item() # this compares the amount of correct predictions and adds them \n",
    "\n",
    "    accuracy = 100 * n_correct / n_samples\n",
    "    print(f\"Accuracy = {accuracy}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
