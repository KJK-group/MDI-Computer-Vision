{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirSimDataset - Resnet50 - Using the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torchinfo\n",
    "import json\n",
    "from torchvision.models.segmentation import fcn\n",
    "import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import airsim \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device chosen GPU: NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Device chosen GPU:\", torch.cuda.get_device_name(device))\n",
    "\n",
    "# Parameters\n",
    "num_classes = 9 # Automatically calculated in the next cell\n",
    "#test_ratio = 20 # 1/test_ratio of samples are for testing\n",
    "\n",
    "# Hyper parameters\n",
    "# num_epochs = 50\n",
    "# batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "# log_directory = f\"runs/MDI-CustomDataset/resnet50/v0.0.3 Adam lr = {learning_rate}, epochs = {num_epochs}, batchsize ={batch_size}\"\n",
    "# writer  = SummaryWriter(log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes/unique RGB values in given image: 9\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# def pil_to_np(img):\n",
    "#     return np.array(img) \n",
    "\n",
    "# The Cityscapes dataset is avaliable in PyTorch\n",
    "# train_dataset = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='train', mode='fine', target_type='semantic', transform=transform, target_transform=pil_to_np)\n",
    "# #test_dataset  = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='test',  mode='fine', target_type='semantic', transform=pil_to_tensor, target_transform=transforms.ToTensor())\n",
    "# val_dataset   = torchvision.datasets.Cityscapes(root='./cityscapesDataset', split='val',   mode='fine', target_type='semantic', transform=transform, target_transform=pil_to_np)\n",
    "\n",
    "# DATA_DIRECTORY = \"AirSimDataset/\"\n",
    "# airSimDataset = np.load(DATA_DIRECTORY)\n",
    "# print(airSimDataset)\n",
    "\n",
    "# Help with glob from https://stackoverflow.com/questions/39195113/how-to-load-multiple-images-in-a-numpy-array\n",
    "# file_list_images  = sorted(glob.glob('MDI-CustomDataset/img_0_0_*.png'))\n",
    "# file_list_targets = sorted(glob.glob('MDI-CustomDataset/img_0_5_*.png'))\n",
    "\n",
    "# dataset_images  = np.array([np.array(Image.open(filename))                for filename in file_list_images])\n",
    "#dataset_depths  = np.array([np.array(airsim.utils.read_pfm(filename)[0])  for filename in file_list_depths])\n",
    "# dataset_targets = np.array([np.array(Image.open(filename))                for filename in file_list_targets])\n",
    "\n",
    "# print(\"Images  shape:\", dataset_images.shape)\n",
    "# print(\"Targets shape:\", dataset_targets.shape)\n",
    "\n",
    "# images = dataset_images[:,:,:,0:3]\n",
    "# targets_RGB = dataset_targets[:,:,:,0:3]\n",
    "\n",
    "# print(\"Images cropped shape:\", images.shape)\n",
    "# print(\"Targets cropped shape:\", targets_RGB.shape)\n",
    "\n",
    "# with torch.no_grad():\n",
    "    \n",
    "    # def unique_rgb_colors_in_img(img):\n",
    "    #     return np.unique(img.reshape(-1, 3), axis=0)\n",
    "\n",
    "    # # Going from 3 target channels into 1\n",
    "    # unique_colors = unique_rgb_colors_in_img(targets_RGB[0])\n",
    "    # num_classes = len(unique_colors)\n",
    "    # print('Number of classes/unique RGB values in given image:', num_classes)\n",
    "    # color_map = torch.tensor(unique_colors, device=device) # finds the unique RGB colors and lists them # 1.1GB\n",
    "\n",
    "    # torch_targets_RGB = torch.tensor(targets_RGB, device=device) # putting it on the GPU and garbage collrcting the cpu one # 1.6GB\n",
    "    # # Create target on the gpu\n",
    "    # targets = torch.zeros(targets_RGB.shape[:3], device=device) # 14.4GB\n",
    "    # # convert to torch tensor and put it on gpu\n",
    "    # #mid = time.perf_counter()\n",
    "    # #print(f\"time gpu moving: {mid - start}\")\n",
    "    # for i, c in enumerate(color_map):\n",
    "    #     # find all pixel equal to the color\n",
    "    #     indices = torch.where(torch.all(torch_targets_RGB == c, dim=-1))\n",
    "    #     # set class\n",
    "    #     # targets[indices] = i + 1\n",
    "    #     targets[indices] = i\n",
    "    # #print(f\"time: {time.perf_counter() - mid}\")\n",
    "\n",
    "    # del color_map\n",
    "    # torch.cuda.empty_cache()\n",
    "    # #del(targets_RGB)\n",
    "\n",
    "    # #targets = torch.unsqueeze(targets, dim=-1)\n",
    "    # images = torch.tensor(images, device=device).permute(0,3,1,2) # Permutes from [84, 720, 1280, 3] to [84, 3, 720, 1280], as that's how PyTorch likes it\n",
    "\n",
    "    # # Pairing the images with the labels - train to test ratio of 5 to 1\n",
    "    # #num_test = int(len(targets)/5) # will return 1/5 integer of the total sample size\n",
    "    # num_test = int(len(targets)/test_ratio) # will return 1/5 integer of the total sample size   \n",
    "    # # train_data = (images[num_test:len(targets)], targets[num_test:len(targets)])\n",
    "    # # test_data = (images[:num_test], targets[:num_test])\n",
    "    # train_data = [(img, t) for img, t in zip(images[num_test:len(targets)], targets[num_test:len(targets)])]\n",
    "    # test_data  = [(img, t) for img, t in zip(images[:num_test], targets[:num_test])]\n",
    "\n",
    "    # # Dataloaders used to batch the paired images\n",
    "    # train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    # test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Splitting the training and testing datasets into smaller batches\n",
    "    # workers = 5\n",
    "    # train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)#,  num_workers=workers)#, pin_memory=True))\n",
    "    # #test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False)#, num_workers=workers)#, pin_memory=True))\n",
    "    # val_loader   = torch.utils.data.DataLoader(dataset=val_dataset,  batch_size=batch_size, shuffle=False)#, num_workers=workers)#, pin_memory=True))\n",
    "\n",
    "    #print('Train Size: ', len(train_dataset))\n",
    "    #print('Test Size : ', len(test_dataset))\n",
    "    #print('Val Size  : ', len(val_dataset))\n",
    "\n",
    "    '''Plot from dataset'''\n",
    "    # fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(24, 16))\n",
    "    # ax[0][0].imshow(images[0].to('cpu').permute(1,2,0))\n",
    "    # ax[0][1].imshow(targets[0].to('cpu'))\n",
    "    # ax[1][0].imshow(images[83].to('cpu').permute(1,2,0))\n",
    "    # ax[1][1].imshow(targets[83].to('cpu'))\n",
    "\n",
    "    '''Plot from dataloader''';\n",
    "    # plot_img, plot_target = iter(train_loader).next()\n",
    "    # plot_img = plot_img[0]\n",
    "    # plot_target = plot_target[0]\n",
    "    # fig, ax = plt.subplots(ncols=2, figsize=(24, 16))\n",
    "    # ax[0].imshow(np.array(plot_img.to('cpu')).transpose(1,2,0)) # transpose(1,2,0) changes the order of the dimensions\n",
    "    # ax[1].imshow(np.array(plot_target.to('cpu')))\n",
    "    # 18.1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading saved model''';\n",
    "model = fcn.fcn_resnet50(pretrained=False, progress=True, num_classes=num_classes, aux_loss=False, pretrained_backbone=True).to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08)\n",
    "\n",
    "loaded_checkpoint = torch.load(\"checkpoint_resnet50_28epochs_customdataset_v0.0.3.pth\")\n",
    "\n",
    "# for param in model.parameters():    # Freezing the startign layers\n",
    "#     # param.requires_grad = False\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.load_state_dict(loaded_checkpoint[\"model_state\"])\n",
    "optimiser.load_state_dict(loaded_checkpoint[\"optimiser_state\"])\n",
    "epoch = loaded_checkpoint[\"epoch\"]\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading new model''';\n",
    "# model = fcn.fcn_resnet50(pretrained=False, progress=True, num_classes=num_classes, aux_loss=False, pretrained_backbone=True).to(device)\n",
    "\n",
    "# # Finetuning\n",
    "# # for param in model.parameters():    # Freezing/unfreezing the starting layers\n",
    "# #     # param.requires_grad = False\n",
    "# #     param.requires_grad = False\n",
    "\n",
    "# optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-8)\n",
    "# criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training'''\n",
    "# # Tensorboard\n",
    "# #writer.add_graph(model.cpu(), val_dataset[0][0])\n",
    "# #writer.close()\n",
    "\n",
    "# # Doing the training now\n",
    "\n",
    "# n_total_steps = len(train_loader)\n",
    "\n",
    "# steps_until_print = batch_size\n",
    "\n",
    "# # stop_training = False\n",
    "# # def signal_handler(sig, frame):\n",
    "# #     print('\\nDetected Ctrl+C, stopping training')\n",
    "# #     stop_training = True\n",
    "# #     print('Saving model')\n",
    "# # signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "# model.train()\n",
    "# print('Starting training')\n",
    "# for epoch in range(num_epochs):\n",
    "#     #if stop_training: break\n",
    "\n",
    "#     # Check for stop - read file for boolean to stopping safely\n",
    "#     with open(\"train.json\") as train_json:\n",
    "#         train_dict = json.load(train_json)\n",
    "#         if train_dict[\"train\"] == \"False\": break\n",
    "\n",
    "#     testing_batches = iter(test_loader) # Every epoch tests the whole dataset once\n",
    "\n",
    "#     for i, (images, targets) in enumerate(train_loader):\n",
    "#             # Check for stop - read file for boolean to stopping safely\n",
    "#         with open(\"train.json\") as train_json:\n",
    "#             train_dict = json.load(train_json)\n",
    "#             if train_dict[\"train\"] == \"False\": break\n",
    "\n",
    "#         images = images.to(device, torch.float32)\n",
    "#         targets = targets.to(device)\n",
    "#         # print('images  shape:', images.shape)\n",
    "#         # print('targets shape:', targets.shape)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)['out']\n",
    "#         # print(\"outputs shape:\", outputs.shape)\n",
    "      \n",
    "#         loss = criterion(outputs, targets.long())\n",
    "\n",
    "#         # Backward pass\n",
    "#         optimiser.zero_grad()   # Clear old gradient values\n",
    "#         loss.backward()         # Calculate the gradients\n",
    "#         optimiser.step()        # Update the model's weights - seen at model.parameters()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "\n",
    "#             # Logging the train accuracy\n",
    "#             pred = torch.argmax(outputs, dim=1)     # Evaluate along the 1st dimension\n",
    "#             batch_pixel_accuracy = (pred == targets).sum().item()/(batch_size*pred.shape[1]*pred.shape[2])\n",
    "#             writer.add_scalar('Accuracy/training', batch_pixel_accuracy, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "#             # Logging the train loss\n",
    "#             writer.add_scalar('Loss/training', loss.item()/steps_until_print, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step\n",
    "\n",
    "#             # For every 5 batches, test one batch. (test:train data ratio is split 1:5)\n",
    "#             if (i+1) % test_ratio == 0:  # Logging the testing loss\n",
    "#                 test_images, test_targets = testing_batches.next()\n",
    "                \n",
    "#                 test_images = test_images.to(device)\n",
    "#                 test_targets = test_targets.to(device)#.squeeze(1)\n",
    "\n",
    "#                 model.eval()\n",
    "#                 test_outputs = model(test_images.float())['out']\n",
    "#                 model.train()\n",
    "                    \n",
    "#                 test_pred = torch.argmax(test_outputs, dim=1)\n",
    "\n",
    "#                 '''Plot test results'''\n",
    "#                 fig, ax = plt.subplots(ncols=3, figsize=(24, 16))\n",
    "#                 ax[0].imshow(test_images[0].to('cpu', torch.uint8).permute(1,2,0)) # transpose(1,2,0) changes the order of the dimensions\n",
    "#                 ax[1].imshow(test_targets[0].to('cpu'))\n",
    "#                 ax[2].imshow(test_pred[0].to('cpu').detach())\n",
    "#                 plt.pause(0.01)\n",
    "#                 '''                     '''\n",
    "\n",
    "#                 # print('test_images  shape:', test_images.shape)\n",
    "#                 # print('test_targets shape:', test_targets.shape)\n",
    "#                 # print('test_outputs shape:', test_outputs.shape)\n",
    "#                 # print('test_pred    shape:', test_pred.shape)\n",
    "\n",
    "#                 # writer.add_images('test/images',      test_images                  , epoch * n_total_steps + i)\n",
    "#                 # writer.add_images('test/targets',     test_targets.unsqueeze(dim=1), epoch * n_total_steps + i)\n",
    "#                 # writer.add_images('test/predictions', test_pred.unsqueeze(dim=1)   , epoch * n_total_steps + i)\n",
    "\n",
    "#                 # Logging the test accuracy\n",
    "#                 test_batch_pixel_accuracy = (test_pred == test_targets).sum().item()/(batch_size*test_pred.shape[1]*test_pred.shape[2])\n",
    "#                 #print('Test batch pixel accuracy', test_batch_pixel_accuracy)\n",
    "#                 writer.add_scalar('Accuracy/testing', test_batch_pixel_accuracy, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "#                 # Logging the test loss\n",
    "#                 test_loss = criterion(test_outputs, test_targets.long())\n",
    "#                 writer.add_scalar('Loss/testing', test_loss.item()/len(test_targets), epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step\n",
    "\n",
    "#                 #writer.add_scalars(\"Accuracy\", {\"train\": batch_pixel_accuracy, \"test\": test_batch_pixel_accuracy}, epoch * n_total_steps + i)\n",
    "\n",
    "#                 print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.5f}')\n",
    "                \n",
    "\n",
    "#     #print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.5f}')\n",
    "\n",
    "# print(\"Training is done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving the model''';\n",
    "#checkpoint = {\n",
    "#    \"epoch\": epoch,\n",
    "#    \"model_state\": model.state_dict(),\n",
    "#    \"optimiser_state\": optimiser.state_dict()\n",
    "#}\n",
    "#torch.save(checkpoint, \"checkpoint_resnet50___.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plotting''';\n",
    "# with torch.no_grad():\n",
    "#     # iterator = iter(test_loader) \n",
    "#     # images, targets = next(iterator)\n",
    "#     # images = images.to(device)\n",
    "\n",
    "#     image = \n",
    "#     target =\n",
    "\n",
    "#     model.eval().to(device)\n",
    "#     output = model(image.to(device))['out']\n",
    "#     pred = torch.argmax(output, dim=1)\n",
    "\n",
    "#     images = image.to('cpu')\n",
    "#     targets = target.to('cpu')\n",
    "#     output = output.to('cpu')\n",
    "#     pred = pred.to('cpu')\n",
    "#     print('image: ', images.shape)\n",
    "#     print('target:', targets.shape)\n",
    "#     print('output:', output.shape)\n",
    "#     print('pred:  ', pred.shape)\n",
    "#     fig, ax = plt.subplots(ncols=3, figsize=(24, 16))\n",
    "#     ax[0].imshow(images[1].squeeze().permute(1,2,0))  # .squeeze() does the same thing as .numpy().transpose(1,2,0) \n",
    "#     ax[1].imshow(targets[1].squeeze()) # .squeeze() does the same thing as .numpy().transpose(1,2,0) \n",
    "#     ax[2].imshow(pred[1].squeeze())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5df1dd228c623f342aea1a559f25a175680dd3acf8687bc2fb53ef86fbd3b1a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
