{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import adabound # https://github.com/Luolc/AdaBound\n",
    "from torchsummary import summary\n",
    "\n",
    "# TorchCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# For notificaiton\n",
    "import AppKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CIFAR-10 - Adam - TorchCAM - Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 20\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "log_directory = f\"runs/CIFAR10/v1.1.2 Adam lr = {learning_rate}, epochs = {num_epochs}, batchsize ={batch_size}\"\n",
    "writer1  = SummaryWriter(log_directory)\n",
    "#writer2 = SummaryWriter(log_directory)\n",
    "\n",
    "# Loading dataset\n",
    "# Since the dataset is in PIL (Python Imaging Library) form, tranform them into tensors of normalised range [-1, 1]\n",
    "transform = transforms.Compose( # this transforms.compose combines multiple tranformations as one\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The CIFAR10 tataset is avaliable in PyTorch\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./cifar10Dataset', train=True,  download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./cifar10Dataset', train=False, download=True, transform=transform)\n",
    "\n",
    "# Splitting the training and testing datasets into smaller batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
    "\n",
    "# Checking a data sample \n",
    "example = iter(test_loader)\n",
    "images, labels = example.next()\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def im_transpose(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, step 782/782, loss = 0.39305\n",
      "Epoch 2/20, step 782/782, loss = 0.23474\n",
      "Epoch 3/20, step 782/782, loss = 0.94358\n",
      "Epoch 4/20, step 782/782, loss = 0.39835\n",
      "Epoch 5/20, step 782/782, loss = 0.33639\n",
      "Epoch 6/20, step 782/782, loss = 0.71343\n",
      "Epoch 7/20, step 782/782, loss = 0.69653\n",
      "Epoch 8/20, step 782/782, loss = 0.93882\n",
      "Epoch 9/20, step 782/782, loss = 0.32701\n",
      "Epoch 10/20, step 782/782, loss = 0.52522\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000003?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000003?line=58'>59</a>\u001b[0m     testing_batches \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(test_loader) \u001b[39m# For every epoch, we want to have tested the whole testing dataset once\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000003?line=60'>61</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000003?line=62'>63</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000003?line=63'>64</a>\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=113'>114</a>\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=115'>116</a>\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=116'>117</a>\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=117'>118</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=119'>120</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/cifar.py?line=120'>121</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py:2830\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py?line=2827'>2828</a>\u001b[0m \u001b[39mif\u001b[39;00m strides \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py?line=2828'>2829</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mtobytes\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py?line=2829'>2830</a>\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py?line=2830'>2831</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py?line=2831'>2832</a>\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)      # Input 3 (RGB), 6 (outputs), 5 (kernel size)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)      # Kernel size of 2 with stride of 2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)     # Input 6 (conv1's output), 16 (outputs), 5 (kernel size)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2)    # Input 16 (conv1's output), 32 (outputs), 5 (kernel size) # Stop here\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)    # Input 32 (conv1's output), 64 (outputs), 3 (kernel size)\n",
    "        # Classification layers\n",
    "        x = self.dropout(x)\n",
    "        self.fc1   = nn.Linear(64*5*5, 120)   # Fully connected linear layer. 16 is the output of conv2 and 5x5 is\n",
    "#                                             the output dimention after conv1->pool->conv2->pool. \n",
    "#                                             The process can be observed in the coming cells.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)        # Output is 10 as we have 10 classes in the CIFAR-10 dataset\n",
    "        self.dropout = nn.Dropout(p=0.10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x.register_hook(self.activations_hook)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 64*5*5) # Flattening x. # -1 makes pytorch infer the dimensionality, which in this case is the number of batches (4).\n",
    "# It does this by looking at the given dimentions, and inferring the last one using the amount of avaliable data/cells.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)         # Don't apply softmax, as it's applied in the used criterion - nn.CrossEntropyLoss()\n",
    "        return x\n",
    "\n",
    "    #def activations_hook(self, grad):\n",
    "    #        self.gradients = grad\n",
    "        \n",
    "\n",
    "#model = ConvNet().to(device) # Comment this if a model is loaded\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08) # Comment this if a model is loaded\n",
    "\n",
    "\n",
    "# Tensorboard\n",
    "writer1.add_graph(model, images)\n",
    "writer1.close()\n",
    "\n",
    "# Doing the training now\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0\n",
    "running_correct = 0\n",
    "running_loss_test = 0\n",
    "\n",
    "steps_until_print = batch_size\n",
    "#print(f'One batch has {len(example)/batch_size} images\\nPrint every {steps_until_print}')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    testing_batches = iter(test_loader) # For every epoch, we want to have tested the whole testing dataset once\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimiser.zero_grad()   # Clear old gradient values\n",
    "        loss.backward()         # Calculate the gradients\n",
    "        optimiser.step()        # Update the model's weights (these are the model parameters(), different from hyperparameters)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add loss to the running loss \n",
    "            running_loss = loss.item()\n",
    "            _, predictions = torch.max(outputs, 1)                  # Evaluate along the 1st dimension\n",
    "\n",
    "            running_correct = (predictions == labels).sum().item()  # We can call .item() as it's a tensor with one item\n",
    "\n",
    "            if (i+1) % steps_until_print == 0:\n",
    "                # Logging the loss\n",
    "                writer1.add_scalar('Loss/training', running_loss/steps_until_print, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "                # Adding the accuracy\n",
    "                writer1.add_scalar('Accuracy/training', running_correct/batch_size*100, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "            # If for every 5 epochs, test one batch. (test:train data ratio is split 1:5)\n",
    "            if (i+1) % 5 == 0:  # Logging the testing loss\n",
    "                test_images, test_labels = testing_batches.next()\n",
    "                \n",
    "                test_images = test_images.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "\n",
    "                test_outputs = model(test_images)\n",
    "\n",
    "                _, test_predictions = torch.max(test_outputs, 1)\n",
    "                test_running_correct = (test_predictions == test_labels).sum().item()\n",
    "                writer1.add_scalar('Accuracy/testing', test_running_correct/batch_size*100, epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step \n",
    "\n",
    "                test_loss = criterion(test_outputs, test_labels)\n",
    "                test_running_loss = test_loss.item()\n",
    "                writer1.add_scalar('Loss/testing', test_running_loss/len(test_labels), epoch * n_total_steps + i) # label of the scalar, actual loss mean, current global step\n",
    "\n",
    "    #writer2.add_scalar('Loss/training', running_loss/steps_until_print, epoch * n_total_steps) # label of the scalar, actual loss mean, current global step\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.5f}')\n",
    "    #print(f'Finished epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "print(\"Training is done\")\n",
    "AppKit.NSBeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\"\"\"checkpoint = {\n",
    "    \"epoch\": 90,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimiser_state\": optimiser.state_dict()\n",
    "}\n",
    "torch.save(checkpoint, \"checkpoint.pth\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why 16\\*5\\*5 in fc1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_dimentions(W, F, P, S): # To read more, look at \"Calculating the output dimentions\" in the HackMD: https://hackmd.io/@6GXCH802RhyTNfXCGTWmOA/BJC32s5RK\n",
    "#   W = input size, F = filter/kernel size, P = padding, S = stride\n",
    "    return (W-F+2*P)/S + 1\n",
    "\n",
    "# self.conv3 = nn.Conv2d(16, 32, 3)    # Input 6 (conv1's output), 32 (outputs), 3 (kernel size)\n",
    "\n",
    "# After conv1\n",
    "output_dimentions(W=32, F=5, P=0, S=1) # Will have 6 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After pool\n",
    "output_dimentions(W=28, F=2, P=0, S=2) # Will have 6 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After conv2\n",
    "output_dimentions(W=14, F=5, P=0, S=1) # Will have 16 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After pool again\n",
    "output_dimentions(W=10, F=2, P=0, S=2) # Will have 16 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After conv3\n",
    "output_dimentions(W=5, F=5, P=2, S=1) # Will have 32 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After conv4\n",
    "output_dimentions(W=5, F=3, P=1, S=1) # Will have 64 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "           Dropout-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-5             [-1, 16, 5, 5]               0\n",
      "            Conv2d-6             [-1, 32, 5, 5]          12,832\n",
      "            Conv2d-7             [-1, 64, 5, 5]          18,496\n",
      "            Linear-8                  [-1, 120]         192,120\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "           Linear-10                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 237,334\n",
      "Trainable params: 237,334\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 1.01\n",
      "----------------------------------------------------------------\n",
      "General network accuracy = 63.69\n",
      "Plane class accuracy: \t \t 62.8%\n",
      "Car class accuracy: \t \t 82.3%\n",
      "Bird class accuracy: \t \t 47.6%\n",
      "Cat class accuracy: \t \t 48.7%\n",
      "Deer class accuracy: \t \t 56.5%\n",
      "Dog class accuracy: \t \t 54.1%\n",
      "Frog class accuracy: \t \t 70.1%\n",
      "Horse class accuracy: \t \t 69.4%\n",
      "Ship class accuracy: \t \t 77.1%\n",
      "Truck class accuracy: \t \t 68.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detailed validation - accuracy for each class\n",
    "\n",
    "model.eval() # Disables zeroed out neurons for better evaluation instead of training\n",
    "\n",
    "summary(model, (3, 32, 32))\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)  # torch.max returns (value, index)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predictions[i]\n",
    "            if(pred == label):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    accuracy = 100 * n_correct / n_samples\n",
    "    print(f\"General network accuracy = {accuracy}\")\n",
    "\n",
    "    for i in range(10):\n",
    "        accuracy = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'{classes[i]} class accuracy: \\t \\t {accuracy}%')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvNet' object has no attribute 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=43'>44</a>\u001b[0m loaded_checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mcheckpoint.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=44'>45</a>\u001b[0m epoch \u001b[39m=\u001b[39m loaded_checkpoint[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=46'>47</a>\u001b[0m model \u001b[39m=\u001b[39m ConvNet()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(loaded_checkpoint[\u001b[39m\"\u001b[39m\u001b[39mmodel_state\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=48'>49</a>\u001b[0m optimiser \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, betas\u001b[39m=\u001b[39m[beta1, beta2], eps\u001b[39m=\u001b[39m\u001b[39m1e-08\u001b[39m)\n",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb Cell 16'\u001b[0m in \u001b[0;36mConvNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=16'>17</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)    \u001b[39m# Input 32 (conv1's output), 64 (outputs), 3 (kernel size)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=17'>18</a>\u001b[0m         \u001b[39m# Classification layers\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=18'>19</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=19'>20</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1   \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m120\u001b[39m)   \u001b[39m# Fully connected linear layer. 16 is the output of conv2 and 5x5 is\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=20'>21</a>\u001b[0m \u001b[39m#                                             the output dimention after conv1->pool->conv2->pool. \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000021?line=21'>22</a>\u001b[0m \u001b[39m#                                             The process can be observed in the coming cells.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1174'>1175</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1175'>1176</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1176'>1177</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1177'>1178</a>\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConvNet' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "# Load last saved checkpoint\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)      # Input 3 (RGB), 6 (outputs), 5 (kernel size)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)      # Kernel size of 2 with stride of 2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)     # Input 6 (conv1's output), 16 (outputs), 5 (kernel size)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2)    # Input 16 (conv1's output), 32 (outputs), 5 (kernel size) # Stop here\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)    # Input 32 (conv1's output), 64 (outputs), 3 (kernel size)\n",
    "        # Classification layers\n",
    "        #x = self.dropout(x)\n",
    "        self.fc1   = nn.Linear(64*5*5, 120)   # Fully connected linear layer. 16 is the output of conv2 and 5x5 is\n",
    "#                                             the output dimention after conv1->pool->conv2->pool. \n",
    "#                                             The process can be observed in the coming cells.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)        # Output is 10 as we have 10 classes in the CIFAR-10 dataset\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x.register_hook(self.activations_hook)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 64*5*5) # Flattening x. # -1 makes pytorch infer the dimensionality, which in this case is the number of batches (4).\n",
    "# It does this by looking at the given dimentions, and inferring the last one using the amount of avaliable data/cells.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)         # Don't apply softmax, as it's applied in the used criterion - nn.CrossEntropyLoss()\n",
    "        return x\n",
    "\n",
    "    #def activations_hook(self, grad):\n",
    "    #        self.gradients = grad\n",
    "\n",
    "loaded_checkpoint = torch.load(\"checkpoint.pth\")\n",
    "epoch = loaded_checkpoint[\"epoch\"]\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "model.load_state_dict(loaded_checkpoint[\"model_state\"])\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08)\n",
    "optimiser.load_state_dict(loaded_checkpoint[\"optimiser_state\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:\t Cat\n",
      "Predicted:\t Dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "cam_extractor = SmoothGradCAMpp(model, input_shape=[3, 32, 32], target_layer=model.conv4)\n",
    "\n",
    "images, labels = example.next()\n",
    "output = model(images)\n",
    "\n",
    "activation_map = cam_extractor(output.squeeze(0).argmax().item(), output)\n",
    "\n",
    "# Plot the image\n",
    "\"\"\"\n",
    "imshow(torchvision.utils.make_grid(images.detach()))\n",
    "\"\"\"\n",
    "# Plot the activation map on the input\n",
    "# Resize the CAM and overlay it\n",
    "result = overlay_mask(to_pil_image(images.reshape(3,32,32)), to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.5)\n",
    "\"\"\"\n",
    "# Display it\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Print real label\n",
    "classes = ('Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
    "print(\"Ground truth:\\t\",classes[labels.item()])\n",
    "# Print predicted label\n",
    "_, predictions = torch.max(output, 1)\n",
    "print(\"Predicted:\\t\", classes[predictions.item()])\n",
    "\"\"\"\n",
    "# Plot the activation map on the output\n",
    "plt.imshow(activation_map[0].squeeze(0).numpy())\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(im_transpose(torchvision.utils.make_grid(images.detach())))\n",
    "ax2.imshow(result)\n",
    "#fig.axes(\"off\")\n",
    "fig.set_size_inches((16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "num_features = model.fc.in_features     # Getting the number of features going into the fully connected layer\n",
    "\n",
    "model.fc = nn.Linear(num_features, 10)  # Redefining the layer with the same input features, but new output features (the amount of classes that we need to classify)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=[beta1, beta2], eps=1e-08) # Comment this if a model is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
      "             ReLU-21             [-1, 64, 8, 8]               0\n",
      "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
      "             ReLU-24             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-25             [-1, 64, 8, 8]               0\n",
      "           Conv2d-26            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
      "             ReLU-28            [-1, 128, 4, 4]               0\n",
      "           Conv2d-29            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-30            [-1, 128, 4, 4]             256\n",
      "           Conv2d-31            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
      "             ReLU-37            [-1, 128, 4, 4]               0\n",
      "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
      "             ReLU-40            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-41            [-1, 128, 4, 4]               0\n",
      "           Conv2d-42            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-43            [-1, 128, 4, 4]             256\n",
      "             ReLU-44            [-1, 128, 4, 4]               0\n",
      "           Conv2d-45            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
      "             ReLU-47            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-55            [-1, 128, 4, 4]               0\n",
      "           Conv2d-56            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 2, 2]             512\n",
      "             ReLU-58            [-1, 256, 2, 2]               0\n",
      "           Conv2d-59            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 2, 2]             512\n",
      "           Conv2d-61            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 2, 2]             512\n",
      "             ReLU-63            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-64            [-1, 256, 2, 2]               0\n",
      "           Conv2d-65            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 2, 2]             512\n",
      "             ReLU-67            [-1, 256, 2, 2]               0\n",
      "           Conv2d-68            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
      "             ReLU-70            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-71            [-1, 256, 2, 2]               0\n",
      "           Conv2d-72            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 2, 2]             512\n",
      "             ReLU-74            [-1, 256, 2, 2]               0\n",
      "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
      "             ReLU-77            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-78            [-1, 256, 2, 2]               0\n",
      "           Conv2d-79            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
      "             ReLU-81            [-1, 256, 2, 2]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-85            [-1, 256, 2, 2]               0\n",
      "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
      "             ReLU-88            [-1, 256, 2, 2]               0\n",
      "           Conv2d-89            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 2, 2]             512\n",
      "             ReLU-91            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-92            [-1, 256, 2, 2]               0\n",
      "           Conv2d-93            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 2, 2]             512\n",
      "             ReLU-95            [-1, 256, 2, 2]               0\n",
      "           Conv2d-96            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
      "             ReLU-98            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-99            [-1, 256, 2, 2]               0\n",
      "          Conv2d-100            [-1, 512, 1, 1]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-102            [-1, 512, 1, 1]               0\n",
      "          Conv2d-103            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 1, 1]           1,024\n",
      "          Conv2d-105            [-1, 512, 1, 1]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-107            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-108            [-1, 512, 1, 1]               0\n",
      "          Conv2d-109            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-111            [-1, 512, 1, 1]               0\n",
      "          Conv2d-112            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-114            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-115            [-1, 512, 1, 1]               0\n",
      "          Conv2d-116            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-118            [-1, 512, 1, 1]               0\n",
      "          Conv2d-119            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-121            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-122            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.98\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 85.14\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000037?line=9'>10</a>\u001b[0m images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000037?line=10'>11</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000037?line=12'>13</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000037?line=14'>15</a>\u001b[0m _, predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)  \u001b[39m# torch.max returns (value, index)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevork/Documents/Uni/6.Semester/Project/learning_sheet05.ipynb#ch0000037?line=15'>16</a>\u001b[0m n_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=247'>248</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=248'>249</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py:240\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=237'>238</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=238'>239</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=239'>240</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=241'>242</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=242'>243</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py:71\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=67'>68</a>\u001b[0m identity \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=69'>70</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=70'>71</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(out)\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=71'>72</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torchvision/models/resnet.py?line=73'>74</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=160'>161</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=162'>163</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=163'>164</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=164'>165</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=165'>166</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=166'>167</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=167'>168</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=168'>169</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=169'>170</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=170'>171</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=171'>172</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=172'>173</a>\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=173'>174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=175'>176</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=176'>177</a>\u001b[0m     bn_training,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=177'>178</a>\u001b[0m     exponential_average_factor,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=178'>179</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=179'>180</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2280\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2266'>2267</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2267'>2268</a>\u001b[0m         batch_norm,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2268'>2269</a>\u001b[0m         (\u001b[39minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2276'>2277</a>\u001b[0m         eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2277'>2278</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2278'>2279</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2279'>2280</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2281'>2282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbatch_norm(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2282'>2283</a>\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39menabled\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2283'>2284</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2248\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2245'>2246</a>\u001b[0m     size_prods \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2246'>2247</a>\u001b[0m \u001b[39mif\u001b[39;00m size_prods \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py?line=2247'>2248</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(size))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)  # torch.max returns (value, index)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predictions[i]\n",
    "            if(pred == label):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    accuracy = 100 * n_correct / n_samples\n",
    "    print(f\"General network accuracy = {accuracy}\")\n",
    "\n",
    "    for i in range(10):\n",
    "        accuracy = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'{classes[i]} class accuracy: \\t \\t {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im(torchvision.utils.make_grid(images.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
